{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96fde08",
   "metadata": {},
   "source": [
    "# ğŸ” 03 - AnÃ¡lise de PadrÃµes com Regex\n",
    "\n",
    "## ğŸ“– VisÃ£o Geral\n",
    "\n",
    "Este notebook realiza anÃ¡lise baseada em expressÃµes regulares para identificar nanomateriais, propriedades funcionais e tÃ©cnicas de preparaÃ§Ã£o nos textos cientÃ­ficos.\n",
    "\n",
    "### ğŸ¯ Responsabilidades\n",
    "\n",
    "- âœ… IdentificaÃ§Ã£o de nanomateriais usando padrÃµes regex avanÃ§ados\n",
    "- âœ… ExtraÃ§Ã£o de propriedades funcionais de tintas e revestimentos\n",
    "- âœ… DetecÃ§Ã£o de tÃ©cnicas de preparaÃ§Ã£o e aplicaÃ§Ã£o\n",
    "- âœ… AnÃ¡lise de co-ocorrÃªncias entre materiais e propriedades\n",
    "- âœ… GeraÃ§Ã£o de matrizes de relacionamento\n",
    "- âœ… PreparaÃ§Ã£o de dados para anÃ¡lise Gemini\n",
    "\n",
    "### ğŸ“¦ DependÃªncias\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- re (regex)\n",
    "- json\n",
    "- plotly (para visualizaÃ§Ãµes)\n",
    "- networkx (para anÃ¡lise de redes)\n",
    "\n",
    "### ğŸ”— Notebooks Relacionados\n",
    "\n",
    "- **Anterior**: `02_carregamento_dados.ipynb`\n",
    "- **PrÃ³ximo**: `04_analise_gemini.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2626952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Plotly disponÃ­vel para visualizaÃ§Ãµes\n",
      "âœ… NetworkX disponÃ­vel para anÃ¡lise de redes\n",
      "\n",
      "ğŸ“¦ Imports concluÃ­dos\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Imports e carregamento de dados\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Set, Optional, Any\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tentar importar bibliotecas opcionais\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    from plotly.subplots import make_subplots\n",
    "    PLOTLY_AVAILABLE = True\n",
    "    print(\"âœ… Plotly disponÃ­vel para visualizaÃ§Ãµes\")\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"âš ï¸ Plotly nÃ£o disponÃ­vel - visualizaÃ§Ãµes desabilitadas\")\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "    NETWORKX_AVAILABLE = True\n",
    "    print(\"âœ… NetworkX disponÃ­vel para anÃ¡lise de redes\")\n",
    "except ImportError:\n",
    "    NETWORKX_AVAILABLE = False\n",
    "    print(\"âš ï¸ NetworkX nÃ£o disponÃ­vel - anÃ¡lise de redes desabilitada\")\n",
    "\n",
    "print(\"\\nğŸ“¦ Imports concluÃ­dos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe07526",
   "metadata": {},
   "source": [
    "## ğŸ”§ Carregamento de ConfiguraÃ§Ãµes e Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd77096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ConfiguraÃ§Ãµes carregadas do sistema\n",
      "   Sistema configurado: True\n",
      "   Nanomateriais disponÃ­veis: 6 categorias\n",
      "   Palavras-chave disponÃ­veis: 4 categorias\n",
      "\n",
      "ğŸ“Š Carregando dados processados...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dados carregados: 9,046 registros Ã— 76 colunas\n",
      "ğŸ“‹ Colunas essenciais presentes: 2/2\n",
      "\n",
      "ğŸ” Colunas relacionadas ao Open Access encontradas: ['Early Access Date', 'Open Access Designations', 'filtrado_open_access']\n",
      "ğŸ“Š Registros jÃ¡ filtrados por Open Access: 9,046\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ Carregamento de configuraÃ§Ãµes e dados\n",
    "\n",
    "# Carregar configuraÃ§Ãµes do sistema\n",
    "config_file = 'config_sistema.json'\n",
    "if os.path.exists(config_file):\n",
    "    with open(config_file, 'r', encoding='utf-8') as f:\n",
    "        config_data = json.load(f)\n",
    "    \n",
    "    SISTEMA_CONFIGURADO = config_data.get('sistema_configurado', False)\n",
    "    PATHS = config_data.get('paths', {})\n",
    "    CONFIG = config_data.get('config', {})\n",
    "    NANOMATERIAIS_DB = config_data.get('nanomateriais', {})\n",
    "    PALAVRAS_CHAVE_DB = config_data.get('palavras_chave', {})\n",
    "    \n",
    "    print(\"âœ… ConfiguraÃ§Ãµes carregadas do sistema\")\n",
    "    print(f\"   Sistema configurado: {SISTEMA_CONFIGURADO}\")\n",
    "    print(f\"   Nanomateriais disponÃ­veis: {len(NANOMATERIAIS_DB)} categorias\")\n",
    "    print(f\"   Palavras-chave disponÃ­veis: {len(PALAVRAS_CHAVE_DB)} categorias\")\n",
    "else:\n",
    "    print(\"âŒ Arquivo de configuraÃ§Ã£o nÃ£o encontrado!\")\n",
    "    print(\"ğŸ’¡ Execute primeiro o notebook '01_configuracao_sistema.ipynb'\")\n",
    "    raise FileNotFoundError(\"ConfiguraÃ§Ã£o do sistema necessÃ¡ria\")\n",
    "\n",
    "# Tentar carregar dados do notebook anterior\n",
    "processed_dir = PATHS.get('processed', './processed/')\n",
    "latest_data_file = os.path.join(processed_dir, 'dataset_wos_latest.csv')\n",
    "\n",
    "if os.path.exists(latest_data_file):\n",
    "    print(f\"\\nğŸ“Š Carregando dados processados...\")\n",
    "    df_data = pd.read_csv(latest_data_file, encoding='utf-8-sig')\n",
    "    print(f\"âœ… Dados carregados: {len(df_data):,} registros Ã— {len(df_data.columns)} colunas\")\n",
    "    \n",
    "    # Verificar colunas essenciais\n",
    "    colunas_essenciais = ['Article Title', 'Abstract']\n",
    "    colunas_presentes = [col for col in colunas_essenciais if col in df_data.columns]\n",
    "    print(f\"ğŸ“‹ Colunas essenciais presentes: {len(colunas_presentes)}/{len(colunas_essenciais)}\")\n",
    "    \n",
    "    if len(colunas_presentes) < len(colunas_essenciais):\n",
    "        print(f\"âš ï¸ Colunas faltantes: {set(colunas_essenciais) - set(colunas_presentes)}\")\n",
    "    \n",
    "    # Verificar colunas de Open Access disponÃ­veis\n",
    "    open_access_columns = [col for col in df_data.columns if 'open' in col.lower() or 'access' in col.lower()]\n",
    "    print(f\"\\nğŸ” Colunas relacionadas ao Open Access encontradas: {open_access_columns}\")\n",
    "    \n",
    "    # Verificar se hÃ¡ coluna de filtro\n",
    "    if 'filtrado_open_access' in df_data.columns:\n",
    "        oa_filtered = df_data['filtrado_open_access'].sum()\n",
    "        print(f\"ğŸ“Š Registros jÃ¡ filtrados por Open Access: {oa_filtered:,}\")\n",
    "else:\n",
    "    print(\"âŒ Dados processados nÃ£o encontrados!\")\n",
    "    print(\"ğŸ’¡ Execute primeiro o notebook '02_carregamento_dados.ipynb'\")\n",
    "    raise FileNotFoundError(\"Dados processados necessÃ¡rios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4576d60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Filtro de Open Access aplicado via coluna 'Open Access Designations': 9,046 registros\n",
      "ğŸ“‰ Registros removidos: 0\n",
      "ğŸ“Š Dataset final para anÃ¡lise regex: 9,046 registros\n",
      "âœ… ConfirmaÃ§Ã£o: Todos os 9,046 registros sÃ£o Open Access\n",
      "\n",
      "ğŸ”’ VERIFICANDO E APLICANDO FILTRO DE OPEN ACCESS\n",
      "==================================================\n",
      "âœ… Dados jÃ¡ estÃ£o filtrados por Open Access: 9,046 registros (100%)\n",
      "\n",
      "âœ… Dataset final para anÃ¡lise: 9,046 registros\n",
      "ğŸ“Š Colunas disponÃ­veis: 76\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Verificar e usar dados filtrados por Open Access se disponÃ­veis\n",
    "if 'Open Access' in df_data.columns:\n",
    "    # Aplicar filtro de Open Access\n",
    "    df_clean = df_data[df_data['Open Access'] == True]\n",
    "    print(f\"ğŸ”’ Filtro de Open Access aplicado: {len(df_clean):,} registros de Open Access encontrados\")\n",
    "    print(f\"ğŸ“‰ Registros removidos (nÃ£o Open Access): {len(df_data) - len(df_clean):,}\")\n",
    "else:\n",
    "    # Verificar outras colunas possÃ­veis de Open Access\n",
    "    possiveis_colunas_oa = ['Open Access Designations', 'OA', 'Acesso Aberto']\n",
    "    coluna_oa_encontrada = None\n",
    "    \n",
    "    for col in possiveis_colunas_oa:\n",
    "        if col in df_data.columns:\n",
    "            coluna_oa_encontrada = col\n",
    "            break\n",
    "    \n",
    "    if coluna_oa_encontrada:\n",
    "        # Filtrar por registros com classificaÃ§Ã£o de Open Access nÃ£o vazia\n",
    "        df_clean = df_data[df_data[coluna_oa_encontrada].notna()]\n",
    "        df_clean = df_clean[df_clean[coluna_oa_encontrada].astype(str).str.strip() != '']\n",
    "        df_clean = df_clean[~df_clean[coluna_oa_encontrada].astype(str).str.lower().isin(['nan', 'none', 'unknown'])]\n",
    "        print(f\"ğŸ”’ Filtro de Open Access aplicado via coluna '{coluna_oa_encontrada}': {len(df_clean):,} registros\")\n",
    "        print(f\"ğŸ“‰ Registros removidos: {len(df_data) - len(df_clean):,}\")\n",
    "    else:\n",
    "        # Verificar se os dados jÃ¡ vieram filtrados (coluna filtrado_open_access)\n",
    "        if 'filtrado_open_access' in df_data.columns:\n",
    "            df_clean = df_data.copy()\n",
    "            registros_oa = df_data['filtrado_open_access'].sum()\n",
    "            print(f\"ğŸ” Dados jÃ¡ filtrados por Open Access: {len(df_clean):,} registros ({registros_oa:,} marcados como Open Access)\")\n",
    "        else:\n",
    "            df_clean = df_data.copy()\n",
    "            print(\"âš ï¸ Nenhuma coluna de Open Access encontrada. Usando todos os dados.\")\n",
    "\n",
    "print(f\"ğŸ“Š Dataset final para anÃ¡lise regex: {len(df_clean):,} registros\")\n",
    "\n",
    "# Verificar se realmente temos dados de Open Access\n",
    "if 'filtrado_open_access' in df_clean.columns:\n",
    "    oa_marcados = df_clean['filtrado_open_access'].sum()\n",
    "    if oa_marcados == len(df_clean):\n",
    "        print(f\"âœ… ConfirmaÃ§Ã£o: Todos os {len(df_clean):,} registros sÃ£o Open Access\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Aviso: {oa_marcados:,} de {len(df_clean):,} registros marcados como Open Access\")\n",
    "        \n",
    "# ğŸ” Aplicar filtro de Open Access se disponÃ­vel\n",
    "print(\"\\nğŸ”’ VERIFICANDO E APLICANDO FILTRO DE OPEN ACCESS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Verificar se dados jÃ¡ foram filtrados\n",
    "if 'filtrado_open_access' in df_data.columns:\n",
    "    # Dados jÃ¡ foram filtrados no notebook anterior\n",
    "    open_access_count = df_data['filtrado_open_access'].sum()\n",
    "    if open_access_count == len(df_data):\n",
    "        print(f\"âœ… Dados jÃ¡ estÃ£o filtrados por Open Access: {len(df_data):,} registros (100%)\")\n",
    "        df_clean = df_data.copy()\n",
    "    else:\n",
    "        print(f\"âš ï¸ Dados parcialmente filtrados. Aplicando filtro completo...\")\n",
    "        df_clean = df_data[df_data['filtrado_open_access'] == True]\n",
    "        print(f\"ğŸ“Š ApÃ³s filtro: {len(df_clean):,} registros Open Access\")\n",
    "else:\n",
    "    # Tentar encontrar colunas de Open Access\n",
    "    open_access_columns = [col for col in df_data.columns if 'open' in col.lower() and 'access' in col.lower()]\n",
    "    \n",
    "    if open_access_columns:\n",
    "        oa_col = open_access_columns[0]\n",
    "        print(f\"ğŸ” Usando coluna: '{oa_col}'\")\n",
    "        \n",
    "        # Filtrar por Open Access\n",
    "        initial_count = len(df_data)\n",
    "        df_clean = df_data[df_data[oa_col].notna()]\n",
    "        df_clean = df_clean[df_clean[oa_col].astype(str).str.strip() != '']\n",
    "        df_clean = df_clean[~df_clean[oa_col].astype(str).str.lower().isin(['nan', 'none', 'unknown', ''])]\n",
    "        \n",
    "        final_count = len(df_clean)\n",
    "        removed_count = initial_count - final_count\n",
    "        \n",
    "        print(f\"ğŸ“Š Registros iniciais: {initial_count:,}\")\n",
    "        print(f\"ğŸ“Š Registros finais: {final_count:,}\")\n",
    "        print(f\"ğŸ—‘ï¸ Registros removidos: {removed_count:,} ({removed_count/initial_count*100:.1f}%)\")\n",
    "        \n",
    "        # Adicionar flag\n",
    "        df_clean['filtrado_open_access'] = True\n",
    "    else:\n",
    "        print(\"âš ï¸ Nenhuma coluna de Open Access encontrada. Usando todos os dados.\")\n",
    "        df_clean = df_data.copy()\n",
    "        df_clean['filtrado_open_access'] = False\n",
    "\n",
    "# Atualizar df_data para usar dados filtrados no resto do notebook\n",
    "df_data = df_clean\n",
    "print(f\"\\nâœ… Dataset final para anÃ¡lise: {len(df_data):,} registros\")\n",
    "print(f\"ğŸ“Š Colunas disponÃ­veis: {len(df_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c5f716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ RESUMO DO CARREGAMENTO DE DADOS:\n",
      "========================================\n",
      "ğŸ“ Dados carregados de: /home/delon/Modelos/modeloCenanoInk/data/processed/dataset_wos_latest.csv\n",
      "ğŸ“Š Total de registros: 9,046\n",
      "ğŸ“‹ Total de colunas: 76\n",
      "âœ… Filtro Open Access: APLICADO\n",
      "ğŸ”’ Registros Open Access: 9,046 (100.0% do total)\n",
      "\n",
      "ğŸ Dataset pronto para anÃ¡lise regex com 9,046 registros\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š Resumo do carregamento e filtro\n",
    "print(\"\\nğŸ“‹ RESUMO DO CARREGAMENTO DE DADOS:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ“ Dados carregados de: {latest_data_file}\")\n",
    "print(f\"ğŸ“Š Total de registros: {len(df_data):,}\")\n",
    "print(f\"ğŸ“‹ Total de colunas: {len(df_data.columns)}\")\n",
    "\n",
    "if 'filtrado_open_access' in df_data.columns:\n",
    "    open_access_aplicado = df_data['filtrado_open_access'].any()\n",
    "    if open_access_aplicado:\n",
    "        print(f\"âœ… Filtro Open Access: APLICADO\")\n",
    "        oa_count = df_data['filtrado_open_access'].sum()\n",
    "        print(f\"ğŸ”’ Registros Open Access: {oa_count:,} ({oa_count/len(df_data)*100:.1f}% do total)\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Filtro Open Access: NÃƒO APLICADO\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Filtro Open Access: COLUNA NÃƒO ENCONTRADA\")\n",
    "\n",
    "print(f\"\\nğŸ Dataset pronto para anÃ¡lise regex com {len(df_data):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26372066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Inicializando analisador regex...\n",
      "ğŸ”§ Compilando padrÃµes regex...\n",
      "âœ… 12 padrÃµes regex compilados\n",
      "âœ… Analisador regex pronto\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ DefiniÃ§Ã£o de padrÃµes regex avanÃ§ados\n",
    "\n",
    "class RegexAnalyzer:\n",
    "    \"\"\"Classe para anÃ¡lise de padrÃµes regex em textos cientÃ­ficos\"\"\"\n",
    "    \n",
    "    def __init__(self, nanomateriais_db: Dict, palavras_chave_db: Dict):\n",
    "        self.nanomateriais_db = nanomateriais_db\n",
    "        self.palavras_chave_db = palavras_chave_db\n",
    "        self.compiled_patterns = {}\n",
    "        self._compile_patterns()\n",
    "    \n",
    "    def _compile_patterns(self):\n",
    "        \"\"\"Compila todos os padrÃµes regex para melhor performance\"\"\"\n",
    "        \n",
    "        print(\"ğŸ”§ Compilando padrÃµes regex...\")\n",
    "        \n",
    "        # PadrÃµes para nanomateriais\n",
    "        for categoria, materiais in self.nanomateriais_db.items():\n",
    "            patterns = []\n",
    "            for material in materiais:\n",
    "                # PadrÃ£o bÃ¡sico\n",
    "                pattern = rf'\\b{re.escape(material)}\\b'\n",
    "                patterns.append(pattern)\n",
    "                \n",
    "                # VariaÃ§Ãµes com nano-prefix\n",
    "                if not material.lower().startswith('nano'):\n",
    "                    nano_pattern = rf'\\bnano[-\\s]?{re.escape(material)}\\b'\n",
    "                    patterns.append(nano_pattern)\n",
    "                \n",
    "                # PadrÃµes para abreviaÃ§Ãµes quÃ­micas\n",
    "                if len(material) <= 6 and material.isupper():\n",
    "                    abbrev_pattern = rf'\\b{re.escape(material)}(?:[\\s-]?NPs?|[\\s-]?nanoparticles?)?\\b'\n",
    "                    patterns.append(abbrev_pattern)\n",
    "            \n",
    "            # Compilar padrÃ£o combinado\n",
    "            combined_pattern = '|'.join(patterns)\n",
    "            self.compiled_patterns[f'nano_{categoria}'] = re.compile(\n",
    "                combined_pattern, re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "        \n",
    "        # PadrÃµes para palavras-chave funcionais\n",
    "        for categoria, palavras in self.palavras_chave_db.items():\n",
    "            patterns = []\n",
    "            for palavra in palavras:\n",
    "                # PadrÃ£o bÃ¡sico com word boundaries\n",
    "                pattern = rf'\\b{re.escape(palavra)}\\b'\n",
    "                patterns.append(pattern)\n",
    "                \n",
    "                # VariaÃ§Ãµes plurais e compostas\n",
    "                if not palavra.endswith('s'):\n",
    "                    plural_pattern = rf'\\b{re.escape(palavra)}s?\\b'\n",
    "                    patterns.append(plural_pattern)\n",
    "            \n",
    "            combined_pattern = '|'.join(patterns)\n",
    "            self.compiled_patterns[f'func_{categoria}'] = re.compile(\n",
    "                combined_pattern, re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "        \n",
    "        # PadrÃµes especiais para medidas e valores\n",
    "        self.compiled_patterns['medidas'] = re.compile(\n",
    "            r'\\b(?:\\d+[.,]?\\d*)\\s*(?:nm|Î¼m|mm|cm|m|ml|l|g|kg|%|Â°C|K|Pa|MPa|GPa)\\b',\n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        \n",
    "        # PadrÃµes para mÃ©todos de sÃ­ntese\n",
    "        synthesis_methods = [\n",
    "            'sol-gel', 'chemical vapor deposition', 'CVD', 'physical vapor deposition', 'PVD',\n",
    "            'electrochemical', 'hydrothermal', 'solvothermal', 'precipitation',\n",
    "            'co-precipitation', 'ball milling', 'spray pyrolysis'\n",
    "        ]\n",
    "        synthesis_pattern = '|'.join([rf'\\b{re.escape(method)}\\b' for method in synthesis_methods])\n",
    "        self.compiled_patterns['sintese'] = re.compile(synthesis_pattern, re.IGNORECASE)\n",
    "        \n",
    "        print(f\"âœ… {len(self.compiled_patterns)} padrÃµes regex compilados\")\n",
    "    \n",
    "    def extract_matches(self, text: str, pattern_category: str) -> List[str]:\n",
    "        \"\"\"Extrai todas as correspondÃªncias de um padrÃ£o especÃ­fico\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return []\n",
    "        \n",
    "        if pattern_category not in self.compiled_patterns:\n",
    "            return []\n",
    "        \n",
    "        matches = self.compiled_patterns[pattern_category].findall(text)\n",
    "        # Limpar e normalizar matches\n",
    "        clean_matches = [match.strip().lower() for match in matches if match.strip()]\n",
    "        return list(set(clean_matches))  # Remover duplicatas\n",
    "    \n",
    "    def extract_all_patterns(self, text: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Extrai todos os padrÃµes de um texto\"\"\"\n",
    "        results = {}\n",
    "        for pattern_name in self.compiled_patterns.keys():\n",
    "            results[pattern_name] = self.extract_matches(text, pattern_name)\n",
    "        return results\n",
    "    \n",
    "    def analyze_text_comprehensive(self, text: str) -> Dict[str, any]:\n",
    "        \"\"\"AnÃ¡lise abrangente de um texto\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return {}\n",
    "        # Iniciando anÃ¡lise abrangente\n",
    "        analysis = {\n",
    "            'text_length': len(text),\n",
    "            'word_count': len(text.split()),\n",
    "            'patterns_found': {},\n",
    "            'total_matches': 0,\n",
    "            'nano_relevance_score': 0,\n",
    "            'functional_relevance_score': 0\n",
    "        }\n",
    "        \n",
    "        # Extrair todos os padrÃµes\n",
    "        all_patterns = self.extract_all_patterns(text)\n",
    "        analysis['patterns_found'] = all_patterns\n",
    "        \n",
    "        # Calcular scores de relevÃ¢ncia\n",
    "        nano_matches = 0\n",
    "        func_matches = 0\n",
    "        \n",
    "        for pattern_name, matches in all_patterns.items():\n",
    "            match_count = len(matches)\n",
    "            analysis['total_matches'] += match_count\n",
    "            \n",
    "            if pattern_name.startswith('nano_'):\n",
    "                nano_matches += match_count\n",
    "            elif pattern_name.startswith('func_'):\n",
    "                func_matches += match_count\n",
    "        \n",
    "        # Normalizar scores (0-100)\n",
    "        if analysis['word_count'] > 0:\n",
    "            analysis['nano_relevance_score'] = min(100, (nano_matches / analysis['word_count']) * 1000)\n",
    "            analysis['functional_relevance_score'] = min(100, (func_matches / analysis['word_count']) * 1000)\n",
    "        \n",
    "        return analysis\n",
    "\n",
    "# Inicializar o analisador\n",
    "print(\"ğŸš€ Inicializando analisador regex...\")\n",
    "regex_analyzer = RegexAnalyzer(NANOMATERIAIS_DB, PALAVRAS_CHAVE_DB)\n",
    "print(\"âœ… Analisador regex pronto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7a53c",
   "metadata": {},
   "source": [
    "## ğŸ”„ AnÃ¡lise em Lote dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "006f711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Iniciando anÃ¡lise regex do dataset filtrado...\n",
      "ğŸ”„ INICIANDO ANÃLISE REGEX EM LOTE\n",
      "========================================\n",
      "ğŸ“Š Total de registros: 9,046\n",
      "ğŸ“¦ Tamanho do lote: 50\n",
      "\n",
      "ğŸ“¦ Processando lote 1/181 (1-50)\n",
      "âœ… Lote concluÃ­do (0.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 2/181 (51-100)\n",
      "âœ… Lote concluÃ­do (0.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 2/181 (51-100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Lote concluÃ­do (1.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 3/181 (101-150)\n",
      "âœ… Lote concluÃ­do (1.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 4/181 (151-200)\n",
      "âœ… Lote concluÃ­do (2.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 5/181 (201-250)\n",
      "âœ… Lote concluÃ­do (2.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 6/181 (251-300)\n",
      "âœ… Lote concluÃ­do (1.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 4/181 (151-200)\n",
      "âœ… Lote concluÃ­do (2.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 5/181 (201-250)\n",
      "âœ… Lote concluÃ­do (2.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 6/181 (251-300)\n",
      "âœ… Lote concluÃ­do (3.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 7/181 (301-350)\n",
      "âœ… Lote concluÃ­do (3.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 7/181 (301-350)\n",
      "âœ… Lote concluÃ­do (3.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 8/181 (351-400)\n",
      "âœ… Lote concluÃ­do (3.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 8/181 (351-400)\n",
      "âœ… Lote concluÃ­do (4.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 9/181 (401-450)\n",
      "âœ… Lote concluÃ­do (4.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 9/181 (401-450)\n",
      "âœ… Lote concluÃ­do (5.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 10/181 (451-500)\n",
      "âœ… Lote concluÃ­do (5.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 10/181 (451-500)\n",
      "âœ… Lote concluÃ­do (5.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 11/181 (501-550)\n",
      "âœ… Lote concluÃ­do (5.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 11/181 (501-550)\n",
      "âœ… Lote concluÃ­do (6.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 12/181 (551-600)\n",
      "âœ… Lote concluÃ­do (6.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 12/181 (551-600)\n",
      "âœ… Lote concluÃ­do (6.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 13/181 (601-650)\n",
      "âœ… Lote concluÃ­do (6.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 13/181 (601-650)\n",
      "âœ… Lote concluÃ­do (7.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 14/181 (651-700)\n",
      "âœ… Lote concluÃ­do (7.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 14/181 (651-700)\n",
      "âœ… Lote concluÃ­do (7.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 15/181 (701-750)\n",
      "âœ… Lote concluÃ­do (7.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 15/181 (701-750)\n",
      "âœ… Lote concluÃ­do (8.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 16/181 (751-800)\n",
      "âœ… Lote concluÃ­do (8.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 16/181 (751-800)\n",
      "âœ… Lote concluÃ­do (8.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 17/181 (801-850)\n",
      "âœ… Lote concluÃ­do (8.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 17/181 (801-850)\n",
      "âœ… Lote concluÃ­do (9.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 18/181 (851-900)\n",
      "âœ… Lote concluÃ­do (9.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 19/181 (901-950)\n",
      "âœ… Lote concluÃ­do (9.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 18/181 (851-900)\n",
      "âœ… Lote concluÃ­do (9.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 19/181 (901-950)\n",
      "âœ… Lote concluÃ­do (10.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 20/181 (951-1000)\n",
      "âœ… Lote concluÃ­do (10.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 20/181 (951-1000)\n",
      "âœ… Lote concluÃ­do (11.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 21/181 (1001-1050)\n",
      "âœ… Lote concluÃ­do (11.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 21/181 (1001-1050)\n",
      "âœ… Lote concluÃ­do (11.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 22/181 (1051-1100)\n",
      "âœ… Lote concluÃ­do (11.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 22/181 (1051-1100)\n",
      "âœ… Lote concluÃ­do (12.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 23/181 (1101-1150)\n",
      "âœ… Lote concluÃ­do (12.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 23/181 (1101-1150)\n",
      "âœ… Lote concluÃ­do (12.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 24/181 (1151-1200)\n",
      "âœ… Lote concluÃ­do (12.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 24/181 (1151-1200)\n",
      "âœ… Lote concluÃ­do (13.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 25/181 (1201-1250)\n",
      "âœ… Lote concluÃ­do (13.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 25/181 (1201-1250)\n",
      "âœ… Lote concluÃ­do (13.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 26/181 (1251-1300)\n",
      "âœ… Lote concluÃ­do (13.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 26/181 (1251-1300)\n",
      "âœ… Lote concluÃ­do (14.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 27/181 (1301-1350)\n",
      "âœ… Lote concluÃ­do (14.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 27/181 (1301-1350)\n",
      "âœ… Lote concluÃ­do (14.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 28/181 (1351-1400)\n",
      "âœ… Lote concluÃ­do (14.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 28/181 (1351-1400)\n",
      "âœ… Lote concluÃ­do (15.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 29/181 (1401-1450)\n",
      "âœ… Lote concluÃ­do (15.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 29/181 (1401-1450)\n",
      "âœ… Lote concluÃ­do (16.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 30/181 (1451-1500)\n",
      "âœ… Lote concluÃ­do (16.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 30/181 (1451-1500)\n",
      "âœ… Lote concluÃ­do (16.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 31/181 (1501-1550)\n",
      "âœ… Lote concluÃ­do (16.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 31/181 (1501-1550)\n",
      "âœ… Lote concluÃ­do (17.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 32/181 (1551-1600)\n",
      "âœ… Lote concluÃ­do (17.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 32/181 (1551-1600)\n",
      "âœ… Lote concluÃ­do (17.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 33/181 (1601-1650)\n",
      "âœ… Lote concluÃ­do (17.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 33/181 (1601-1650)\n",
      "âœ… Lote concluÃ­do (18.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 34/181 (1651-1700)\n",
      "âœ… Lote concluÃ­do (18.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 34/181 (1651-1700)\n",
      "âœ… Lote concluÃ­do (18.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 35/181 (1701-1750)\n",
      "âœ… Lote concluÃ­do (18.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 35/181 (1701-1750)\n",
      "âœ… Lote concluÃ­do (19.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 36/181 (1751-1800)\n",
      "âœ… Lote concluÃ­do (19.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 36/181 (1751-1800)\n",
      "âœ… Lote concluÃ­do (19.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 37/181 (1801-1850)\n",
      "âœ… Lote concluÃ­do (19.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 37/181 (1801-1850)\n",
      "âœ… Lote concluÃ­do (20.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 38/181 (1851-1900)\n",
      "âœ… Lote concluÃ­do (20.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 38/181 (1851-1900)\n",
      "âœ… Lote concluÃ­do (21.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 39/181 (1901-1950)\n",
      "âœ… Lote concluÃ­do (21.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 39/181 (1901-1950)\n",
      "âœ… Lote concluÃ­do (21.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 40/181 (1951-2000)\n",
      "âœ… Lote concluÃ­do (21.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 40/181 (1951-2000)\n",
      "âœ… Lote concluÃ­do (22.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 41/181 (2001-2050)\n",
      "âœ… Lote concluÃ­do (22.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 41/181 (2001-2050)\n",
      "âœ… Lote concluÃ­do (22.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 42/181 (2051-2100)\n",
      "âœ… Lote concluÃ­do (22.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 42/181 (2051-2100)\n",
      "âœ… Lote concluÃ­do (23.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 43/181 (2101-2150)\n",
      "âœ… Lote concluÃ­do (23.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 43/181 (2101-2150)\n",
      "âœ… Lote concluÃ­do (23.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 44/181 (2151-2200)\n",
      "âœ… Lote concluÃ­do (23.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 44/181 (2151-2200)\n",
      "âœ… Lote concluÃ­do (24.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 45/181 (2201-2250)\n",
      "âœ… Lote concluÃ­do (24.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 45/181 (2201-2250)\n",
      "âœ… Lote concluÃ­do (24.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 46/181 (2251-2300)\n",
      "âœ… Lote concluÃ­do (24.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 46/181 (2251-2300)\n",
      "âœ… Lote concluÃ­do (25.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 47/181 (2301-2350)\n",
      "âœ… Lote concluÃ­do (25.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 47/181 (2301-2350)\n",
      "âœ… Lote concluÃ­do (26.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 48/181 (2351-2400)\n",
      "âœ… Lote concluÃ­do (26.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 48/181 (2351-2400)\n",
      "âœ… Lote concluÃ­do (26.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 49/181 (2401-2450)\n",
      "âœ… Lote concluÃ­do (26.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 49/181 (2401-2450)\n",
      "âœ… Lote concluÃ­do (27.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 50/181 (2451-2500)\n",
      "âœ… Lote concluÃ­do (27.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 50/181 (2451-2500)\n",
      "âœ… Lote concluÃ­do (27.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 51/181 (2501-2550)\n",
      "âœ… Lote concluÃ­do (27.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 51/181 (2501-2550)\n",
      "âœ… Lote concluÃ­do (28.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 52/181 (2551-2600)\n",
      "âœ… Lote concluÃ­do (28.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 52/181 (2551-2600)\n",
      "âœ… Lote concluÃ­do (28.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 53/181 (2601-2650)\n",
      "âœ… Lote concluÃ­do (28.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 53/181 (2601-2650)\n",
      "âœ… Lote concluÃ­do (29.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 54/181 (2651-2700)\n",
      "âœ… Lote concluÃ­do (29.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 54/181 (2651-2700)\n",
      "âœ… Lote concluÃ­do (29.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 55/181 (2701-2750)\n",
      "âœ… Lote concluÃ­do (29.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 55/181 (2701-2750)\n",
      "âœ… Lote concluÃ­do (30.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 56/181 (2751-2800)\n",
      "âœ… Lote concluÃ­do (30.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 56/181 (2751-2800)\n",
      "âœ… Lote concluÃ­do (30.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 57/181 (2801-2850)\n",
      "âœ… Lote concluÃ­do (30.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 57/181 (2801-2850)\n",
      "âœ… Lote concluÃ­do (31.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 58/181 (2851-2900)\n",
      "âœ… Lote concluÃ­do (31.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 58/181 (2851-2900)\n",
      "âœ… Lote concluÃ­do (32.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 59/181 (2901-2950)\n",
      "âœ… Lote concluÃ­do (32.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 59/181 (2901-2950)\n",
      "âœ… Lote concluÃ­do (32.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 60/181 (2951-3000)\n",
      "âœ… Lote concluÃ­do (32.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 60/181 (2951-3000)\n",
      "âœ… Lote concluÃ­do (33.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 61/181 (3001-3050)\n",
      "âœ… Lote concluÃ­do (33.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 61/181 (3001-3050)\n",
      "âœ… Lote concluÃ­do (33.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 62/181 (3051-3100)\n",
      "âœ… Lote concluÃ­do (33.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 62/181 (3051-3100)\n",
      "âœ… Lote concluÃ­do (34.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 63/181 (3101-3150)\n",
      "âœ… Lote concluÃ­do (34.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 63/181 (3101-3150)\n",
      "âœ… Lote concluÃ­do (34.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 64/181 (3151-3200)\n",
      "âœ… Lote concluÃ­do (34.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 64/181 (3151-3200)\n",
      "âœ… Lote concluÃ­do (35.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 65/181 (3201-3250)\n",
      "âœ… Lote concluÃ­do (35.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 65/181 (3201-3250)\n",
      "âœ… Lote concluÃ­do (35.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 66/181 (3251-3300)\n",
      "âœ… Lote concluÃ­do (35.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 66/181 (3251-3300)\n",
      "âœ… Lote concluÃ­do (36.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 67/181 (3301-3350)\n",
      "âœ… Lote concluÃ­do (36.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 67/181 (3301-3350)\n",
      "âœ… Lote concluÃ­do (37.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 68/181 (3351-3400)\n",
      "âœ… Lote concluÃ­do (37.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 69/181 (3401-3450)\n",
      "âœ… Lote concluÃ­do (37.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 68/181 (3351-3400)\n",
      "âœ… Lote concluÃ­do (37.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 69/181 (3401-3450)\n",
      "âœ… Lote concluÃ­do (38.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 70/181 (3451-3500)\n",
      "âœ… Lote concluÃ­do (38.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 70/181 (3451-3500)\n",
      "âœ… Lote concluÃ­do (38.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 71/181 (3501-3550)\n",
      "âœ… Lote concluÃ­do (38.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 71/181 (3501-3550)\n",
      "âœ… Lote concluÃ­do (39.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 72/181 (3551-3600)\n",
      "âœ… Lote concluÃ­do (39.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 72/181 (3551-3600)\n",
      "âœ… Lote concluÃ­do (39.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 73/181 (3601-3650)\n",
      "âœ… Lote concluÃ­do (39.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 73/181 (3601-3650)\n",
      "âœ… Lote concluÃ­do (40.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 74/181 (3651-3700)\n",
      "âœ… Lote concluÃ­do (40.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 74/181 (3651-3700)\n",
      "âœ… Lote concluÃ­do (40.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 75/181 (3701-3750)\n",
      "âœ… Lote concluÃ­do (41.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 76/181 (3751-3800)\n",
      "âœ… Lote concluÃ­do (40.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 75/181 (3701-3750)\n",
      "âœ… Lote concluÃ­do (41.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 76/181 (3751-3800)\n",
      "âœ… Lote concluÃ­do (42.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 77/181 (3801-3850)\n",
      "âœ… Lote concluÃ­do (42.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 77/181 (3801-3850)\n",
      "âœ… Lote concluÃ­do (42.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 78/181 (3851-3900)\n",
      "âœ… Lote concluÃ­do (43.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 79/181 (3901-3950)\n",
      "âœ… Lote concluÃ­do (42.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 78/181 (3851-3900)\n",
      "âœ… Lote concluÃ­do (43.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 79/181 (3901-3950)\n",
      "âœ… Lote concluÃ­do (43.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 80/181 (3951-4000)\n",
      "âœ… Lote concluÃ­do (43.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 80/181 (3951-4000)\n",
      "âœ… Lote concluÃ­do (44.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 81/181 (4001-4050)\n",
      "âœ… Lote concluÃ­do (44.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 82/181 (4051-4100)\n",
      "âœ… Lote concluÃ­do (44.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 81/181 (4001-4050)\n",
      "âœ… Lote concluÃ­do (44.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 82/181 (4051-4100)\n",
      "âœ… Lote concluÃ­do (45.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 83/181 (4101-4150)\n",
      "âœ… Lote concluÃ­do (45.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 83/181 (4101-4150)\n",
      "âœ… Lote concluÃ­do (45.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 84/181 (4151-4200)\n",
      "âœ… Lote concluÃ­do (45.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 84/181 (4151-4200)\n",
      "âœ… Lote concluÃ­do (46.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 85/181 (4201-4250)\n",
      "âœ… Lote concluÃ­do (46.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 85/181 (4201-4250)\n",
      "âœ… Lote concluÃ­do (47.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 86/181 (4251-4300)\n",
      "âœ… Lote concluÃ­do (47.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 86/181 (4251-4300)\n",
      "âœ… Lote concluÃ­do (47.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 87/181 (4301-4350)\n",
      "âœ… Lote concluÃ­do (48.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 88/181 (4351-4400)\n",
      "âœ… Lote concluÃ­do (47.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 87/181 (4301-4350)\n",
      "âœ… Lote concluÃ­do (48.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 88/181 (4351-4400)\n",
      "âœ… Lote concluÃ­do (48.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 89/181 (4401-4450)\n",
      "âœ… Lote concluÃ­do (48.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 89/181 (4401-4450)\n",
      "âœ… Lote concluÃ­do (49.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 90/181 (4451-4500)\n",
      "âœ… Lote concluÃ­do (49.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 90/181 (4451-4500)\n",
      "âœ… Lote concluÃ­do (49.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 91/181 (4501-4550)\n",
      "âœ… Lote concluÃ­do (49.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 91/181 (4501-4550)\n",
      "âœ… Lote concluÃ­do (50.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 92/181 (4551-4600)\n",
      "âœ… Lote concluÃ­do (50.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 92/181 (4551-4600)\n",
      "âœ… Lote concluÃ­do (50.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 93/181 (4601-4650)\n",
      "âœ… Lote concluÃ­do (50.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 93/181 (4601-4650)\n",
      "âœ… Lote concluÃ­do (51.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 94/181 (4651-4700)\n",
      "âœ… Lote concluÃ­do (51.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 94/181 (4651-4700)\n",
      "âœ… Lote concluÃ­do (51.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 95/181 (4701-4750)\n",
      "âœ… Lote concluÃ­do (51.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 95/181 (4701-4750)\n",
      "âœ… Lote concluÃ­do (52.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 96/181 (4751-4800)\n",
      "âœ… Lote concluÃ­do (52.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 96/181 (4751-4800)\n",
      "âœ… Lote concluÃ­do (53.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 97/181 (4801-4850)\n",
      "âœ… Lote concluÃ­do (53.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 97/181 (4801-4850)\n",
      "âœ… Lote concluÃ­do (53.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 98/181 (4851-4900)\n",
      "âœ… Lote concluÃ­do (53.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 98/181 (4851-4900)\n",
      "âœ… Lote concluÃ­do (54.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 99/181 (4901-4950)\n",
      "âœ… Lote concluÃ­do (54.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 100/181 (4951-5000)\n",
      "âœ… Lote concluÃ­do (54.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 99/181 (4901-4950)\n",
      "âœ… Lote concluÃ­do (54.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 100/181 (4951-5000)\n",
      "âœ… Lote concluÃ­do (55.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 101/181 (5001-5050)\n",
      "âœ… Lote concluÃ­do (55.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 101/181 (5001-5050)\n",
      "âœ… Lote concluÃ­do (55.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 102/181 (5051-5100)\n",
      "âœ… Lote concluÃ­do (55.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 102/181 (5051-5100)\n",
      "âœ… Lote concluÃ­do (56.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 103/181 (5101-5150)\n",
      "âœ… Lote concluÃ­do (56.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 103/181 (5101-5150)\n",
      "âœ… Lote concluÃ­do (56.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 104/181 (5151-5200)\n",
      "âœ… Lote concluÃ­do (56.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 104/181 (5151-5200)\n",
      "âœ… Lote concluÃ­do (57.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 105/181 (5201-5250)\n",
      "âœ… Lote concluÃ­do (57.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 105/181 (5201-5250)\n",
      "âœ… Lote concluÃ­do (58.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 106/181 (5251-5300)\n",
      "âœ… Lote concluÃ­do (58.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 106/181 (5251-5300)\n",
      "âœ… Lote concluÃ­do (58.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 107/181 (5301-5350)\n",
      "âœ… Lote concluÃ­do (58.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 107/181 (5301-5350)\n",
      "âœ… Lote concluÃ­do (59.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 108/181 (5351-5400)\n",
      "âœ… Lote concluÃ­do (59.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 109/181 (5401-5450)\n",
      "âœ… Lote concluÃ­do (59.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 108/181 (5351-5400)\n",
      "âœ… Lote concluÃ­do (59.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 109/181 (5401-5450)\n",
      "âœ… Lote concluÃ­do (60.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 110/181 (5451-5500)\n",
      "âœ… Lote concluÃ­do (60.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 111/181 (5501-5550)\n",
      "âœ… Lote concluÃ­do (60.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 110/181 (5451-5500)\n",
      "âœ… Lote concluÃ­do (60.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 111/181 (5501-5550)\n",
      "âœ… Lote concluÃ­do (61.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 112/181 (5551-5600)\n",
      "âœ… Lote concluÃ­do (61.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 112/181 (5551-5600)\n",
      "âœ… Lote concluÃ­do (61.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 113/181 (5601-5650)\n",
      "âœ… Lote concluÃ­do (62.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 114/181 (5651-5700)\n",
      "âœ… Lote concluÃ­do (61.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 113/181 (5601-5650)\n",
      "âœ… Lote concluÃ­do (62.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 114/181 (5651-5700)\n",
      "âœ… Lote concluÃ­do (63.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 115/181 (5701-5750)\n",
      "âœ… Lote concluÃ­do (63.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 115/181 (5701-5750)\n",
      "âœ… Lote concluÃ­do (63.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 116/181 (5751-5800)\n",
      "âœ… Lote concluÃ­do (63.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 116/181 (5751-5800)\n",
      "âœ… Lote concluÃ­do (64.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 117/181 (5801-5850)\n",
      "âœ… Lote concluÃ­do (64.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 117/181 (5801-5850)\n",
      "âœ… Lote concluÃ­do (64.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 118/181 (5851-5900)\n",
      "âœ… Lote concluÃ­do (65.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 119/181 (5901-5950)\n",
      "âœ… Lote concluÃ­do (64.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 118/181 (5851-5900)\n",
      "âœ… Lote concluÃ­do (65.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 119/181 (5901-5950)\n",
      "âœ… Lote concluÃ­do (65.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 120/181 (5951-6000)\n",
      "âœ… Lote concluÃ­do (65.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 120/181 (5951-6000)\n",
      "âœ… Lote concluÃ­do (66.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 121/181 (6001-6050)\n",
      "âœ… Lote concluÃ­do (66.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 121/181 (6001-6050)\n",
      "âœ… Lote concluÃ­do (66.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 122/181 (6051-6100)\n",
      "âœ… Lote concluÃ­do (66.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 122/181 (6051-6100)\n",
      "âœ… Lote concluÃ­do (67.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 123/181 (6101-6150)\n",
      "âœ… Lote concluÃ­do (67.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 123/181 (6101-6150)\n",
      "âœ… Lote concluÃ­do (68.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 124/181 (6151-6200)\n",
      "âœ… Lote concluÃ­do (68.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 124/181 (6151-6200)\n",
      "âœ… Lote concluÃ­do (68.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 125/181 (6201-6250)\n",
      "âœ… Lote concluÃ­do (68.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 125/181 (6201-6250)\n",
      "âœ… Lote concluÃ­do (69.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 126/181 (6251-6300)\n",
      "âœ… Lote concluÃ­do (69.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 126/181 (6251-6300)\n",
      "âœ… Lote concluÃ­do (69.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 127/181 (6301-6350)\n",
      "âœ… Lote concluÃ­do (69.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 127/181 (6301-6350)\n",
      "âœ… Lote concluÃ­do (70.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 128/181 (6351-6400)\n",
      "âœ… Lote concluÃ­do (70.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 128/181 (6351-6400)\n",
      "âœ… Lote concluÃ­do (70.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 129/181 (6401-6450)\n",
      "âœ… Lote concluÃ­do (70.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 129/181 (6401-6450)\n",
      "âœ… Lote concluÃ­do (71.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 130/181 (6451-6500)\n",
      "âœ… Lote concluÃ­do (71.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 130/181 (6451-6500)\n",
      "âœ… Lote concluÃ­do (71.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 131/181 (6501-6550)\n",
      "âœ… Lote concluÃ­do (71.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 131/181 (6501-6550)\n",
      "âœ… Lote concluÃ­do (72.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 132/181 (6551-6600)\n",
      "âœ… Lote concluÃ­do (72.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 132/181 (6551-6600)\n",
      "âœ… Lote concluÃ­do (72.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 133/181 (6601-6650)\n",
      "âœ… Lote concluÃ­do (73.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 134/181 (6651-6700)\n",
      "âœ… Lote concluÃ­do (72.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 133/181 (6601-6650)\n",
      "âœ… Lote concluÃ­do (73.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 134/181 (6651-6700)\n",
      "âœ… Lote concluÃ­do (74.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 135/181 (6701-6750)\n",
      "âœ… Lote concluÃ­do (74.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 135/181 (6701-6750)\n",
      "âœ… Lote concluÃ­do (74.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 136/181 (6751-6800)\n",
      "âœ… Lote concluÃ­do (74.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 136/181 (6751-6800)\n",
      "âœ… Lote concluÃ­do (75.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 137/181 (6801-6850)\n",
      "âœ… Lote concluÃ­do (75.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 137/181 (6801-6850)\n",
      "âœ… Lote concluÃ­do (75.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 138/181 (6851-6900)\n",
      "âœ… Lote concluÃ­do (75.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 138/181 (6851-6900)\n",
      "âœ… Lote concluÃ­do (76.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 139/181 (6901-6950)\n",
      "âœ… Lote concluÃ­do (76.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 139/181 (6901-6950)\n",
      "âœ… Lote concluÃ­do (76.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 140/181 (6951-7000)\n",
      "âœ… Lote concluÃ­do (76.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 140/181 (6951-7000)\n",
      "âœ… Lote concluÃ­do (77.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 141/181 (7001-7050)\n",
      "âœ… Lote concluÃ­do (77.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 141/181 (7001-7050)\n",
      "âœ… Lote concluÃ­do (77.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 142/181 (7051-7100)\n",
      "âœ… Lote concluÃ­do (77.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 142/181 (7051-7100)\n",
      "âœ… Lote concluÃ­do (78.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 143/181 (7101-7150)\n",
      "âœ… Lote concluÃ­do (78.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 143/181 (7101-7150)\n",
      "âœ… Lote concluÃ­do (79.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 144/181 (7151-7200)\n",
      "âœ… Lote concluÃ­do (79.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 144/181 (7151-7200)\n",
      "âœ… Lote concluÃ­do (79.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 145/181 (7201-7250)\n",
      "âœ… Lote concluÃ­do (79.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 145/181 (7201-7250)\n",
      "âœ… Lote concluÃ­do (80.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 146/181 (7251-7300)\n",
      "âœ… Lote concluÃ­do (80.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 146/181 (7251-7300)\n",
      "âœ… Lote concluÃ­do (80.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 147/181 (7301-7350)\n",
      "âœ… Lote concluÃ­do (81.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 148/181 (7351-7400)\n",
      "âœ… Lote concluÃ­do (80.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 147/181 (7301-7350)\n",
      "âœ… Lote concluÃ­do (81.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 148/181 (7351-7400)\n",
      "âœ… Lote concluÃ­do (81.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 149/181 (7401-7450)\n",
      "âœ… Lote concluÃ­do (81.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 149/181 (7401-7450)\n",
      "âœ… Lote concluÃ­do (82.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 150/181 (7451-7500)\n",
      "âœ… Lote concluÃ­do (82.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 151/181 (7501-7550)\n",
      "âœ… Lote concluÃ­do (82.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 150/181 (7451-7500)\n",
      "âœ… Lote concluÃ­do (82.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 151/181 (7501-7550)\n",
      "âœ… Lote concluÃ­do (83.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 152/181 (7551-7600)\n",
      "âœ… Lote concluÃ­do (83.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 152/181 (7551-7600)\n",
      "âœ… Lote concluÃ­do (84.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 153/181 (7601-7650)\n",
      "âœ… Lote concluÃ­do (84.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 153/181 (7601-7650)\n",
      "âœ… Lote concluÃ­do (84.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 154/181 (7651-7700)\n",
      "âœ… Lote concluÃ­do (84.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 154/181 (7651-7700)\n",
      "âœ… Lote concluÃ­do (85.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 155/181 (7701-7750)\n",
      "âœ… Lote concluÃ­do (85.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 156/181 (7751-7800)\n",
      "âœ… Lote concluÃ­do (85.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 155/181 (7701-7750)\n",
      "âœ… Lote concluÃ­do (85.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 156/181 (7751-7800)\n",
      "âœ… Lote concluÃ­do (86.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 157/181 (7801-7850)\n",
      "âœ… Lote concluÃ­do (86.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 158/181 (7851-7900)\n",
      "âœ… Lote concluÃ­do (86.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 157/181 (7801-7850)\n",
      "âœ… Lote concluÃ­do (86.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 158/181 (7851-7900)\n",
      "âœ… Lote concluÃ­do (87.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 159/181 (7901-7950)\n",
      "âœ… Lote concluÃ­do (87.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 159/181 (7901-7950)\n",
      "âœ… Lote concluÃ­do (87.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 160/181 (7951-8000)\n",
      "âœ… Lote concluÃ­do (87.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 160/181 (7951-8000)\n",
      "âœ… Lote concluÃ­do (88.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 161/181 (8001-8050)\n",
      "âœ… Lote concluÃ­do (88.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 161/181 (8001-8050)\n",
      "âœ… Lote concluÃ­do (89.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 162/181 (8051-8100)\n",
      "âœ… Lote concluÃ­do (89.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 162/181 (8051-8100)\n",
      "âœ… Lote concluÃ­do (89.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 163/181 (8101-8150)\n",
      "âœ… Lote concluÃ­do (89.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 163/181 (8101-8150)\n",
      "âœ… Lote concluÃ­do (90.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 164/181 (8151-8200)\n",
      "âœ… Lote concluÃ­do (90.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 164/181 (8151-8200)\n",
      "âœ… Lote concluÃ­do (90.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 165/181 (8201-8250)\n",
      "âœ… Lote concluÃ­do (90.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 165/181 (8201-8250)\n",
      "âœ… Lote concluÃ­do (91.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 166/181 (8251-8300)\n",
      "âœ… Lote concluÃ­do (91.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 166/181 (8251-8300)\n",
      "âœ… Lote concluÃ­do (91.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 167/181 (8301-8350)\n",
      "âœ… Lote concluÃ­do (91.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 167/181 (8301-8350)\n",
      "âœ… Lote concluÃ­do (92.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 168/181 (8351-8400)\n",
      "âœ… Lote concluÃ­do (92.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 168/181 (8351-8400)\n",
      "âœ… Lote concluÃ­do (92.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 169/181 (8401-8450)\n",
      "âœ… Lote concluÃ­do (92.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 169/181 (8401-8450)\n",
      "âœ… Lote concluÃ­do (93.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 170/181 (8451-8500)\n",
      "âœ… Lote concluÃ­do (93.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 170/181 (8451-8500)\n",
      "âœ… Lote concluÃ­do (93.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 171/181 (8501-8550)\n",
      "âœ… Lote concluÃ­do (93.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 171/181 (8501-8550)\n",
      "âœ… Lote concluÃ­do (94.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 172/181 (8551-8600)\n",
      "âœ… Lote concluÃ­do (94.5% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 172/181 (8551-8600)\n",
      "âœ… Lote concluÃ­do (95.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 173/181 (8601-8650)\n",
      "âœ… Lote concluÃ­do (95.0% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 173/181 (8601-8650)\n",
      "âœ… Lote concluÃ­do (95.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 174/181 (8651-8700)\n",
      "âœ… Lote concluÃ­do (95.6% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 174/181 (8651-8700)\n",
      "âœ… Lote concluÃ­do (96.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 175/181 (8701-8750)\n",
      "âœ… Lote concluÃ­do (96.1% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 175/181 (8701-8750)\n",
      "âœ… Lote concluÃ­do (96.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 176/181 (8751-8800)\n",
      "âœ… Lote concluÃ­do (96.7% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 176/181 (8751-8800)\n",
      "âœ… Lote concluÃ­do (97.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 177/181 (8801-8850)\n",
      "âœ… Lote concluÃ­do (97.2% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 177/181 (8801-8850)\n",
      "âœ… Lote concluÃ­do (97.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 178/181 (8851-8900)\n",
      "âœ… Lote concluÃ­do (97.8% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 178/181 (8851-8900)\n",
      "âœ… Lote concluÃ­do (98.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 179/181 (8901-8950)\n",
      "âœ… Lote concluÃ­do (98.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 180/181 (8951-9000)\n",
      "âœ… Lote concluÃ­do (98.3% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 179/181 (8901-8950)\n",
      "âœ… Lote concluÃ­do (98.9% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 180/181 (8951-9000)\n",
      "âœ… Lote concluÃ­do (99.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 181/181 (9001-9046)\n",
      "âœ… Lote concluÃ­do (100.0% total)\n",
      "\n",
      "ğŸ‰ ANÃLISE REGEX CONCLUÃDA\n",
      "ğŸ“Š Registros processados: 9,046\n",
      "âœ… AnÃ¡lise regex concluÃ­da\n",
      "âœ… Lote concluÃ­do (99.4% total)\n",
      "\n",
      "ğŸ“¦ Processando lote 181/181 (9001-9046)\n",
      "âœ… Lote concluÃ­do (100.0% total)\n",
      "\n",
      "ğŸ‰ ANÃLISE REGEX CONCLUÃDA\n",
      "ğŸ“Š Registros processados: 9,046\n",
      "âœ… AnÃ¡lise regex concluÃ­da\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”„ AnÃ¡lise em lote dos dados\n",
    "\n",
    "def analyze_dataset_regex(df: pd.DataFrame, analyzer: RegexAnalyzer, \n",
    "                         batch_size: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"Analisa todo o dataset usando regex em lotes para melhor performance\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”„ INICIANDO ANÃLISE REGEX EM LOTE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    total_records = len(df)\n",
    "    print(f\"ğŸ“Š Total de registros: {total_records:,}\")\n",
    "    print(f\"ğŸ“¦ Tamanho do lote: {batch_size}\")\n",
    "    \n",
    "    # Preparar DataFrame resultado\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    # Colunas para armazenar resultados\n",
    "    resultado_colunas = [\n",
    "        'nano_relevance_score', 'functional_relevance_score', 'total_matches',\n",
    "        'nanomateriais_encontrados', 'propriedades_funcionais', 'metodos_sintese',\n",
    "        'medidas_encontradas', 'analise_completa'\n",
    "    ]\n",
    "    \n",
    "    for col in resultado_colunas:\n",
    "        df_result[col] = None\n",
    "    \n",
    "    # Processar em lotes\n",
    "    total_batches = (total_records + batch_size - 1) // batch_size\n",
    "    \n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, total_records)\n",
    "        \n",
    "        print(f\"\\nğŸ“¦ Processando lote {batch_idx + 1}/{total_batches} ({start_idx+1}-{end_idx})\")\n",
    "        \n",
    "        # Processar registros do lote\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            # Combinar tÃ­tulo e abstract para anÃ¡lise\n",
    "            titulo = str(df_result.iloc[idx].get('Article Title', ''))\n",
    "            abstract = str(df_result.iloc[idx].get('Abstract', ''))\n",
    "            texto_completo = f\"{titulo} {abstract}\".strip()\n",
    "            \n",
    "            if not texto_completo or texto_completo == 'nan nan':\n",
    "                continue\n",
    "            \n",
    "            # Analisar texto\n",
    "            analise = analyzer.analyze_text_comprehensive(texto_completo)\n",
    "            \n",
    "            # Extrair informaÃ§Ãµes especÃ­ficas\n",
    "            patterns_found = analise.get('patterns_found', {})\n",
    "            \n",
    "            # Coletar nanomateriais\n",
    "            nanomateriais = []\n",
    "            for pattern_name, matches in patterns_found.items():\n",
    "                if pattern_name.startswith('nano_'):\n",
    "                    nanomateriais.extend(matches)\n",
    "            \n",
    "            # Coletar propriedades funcionais\n",
    "            propriedades = []\n",
    "            for pattern_name, matches in patterns_found.items():\n",
    "                if pattern_name.startswith('func_'):\n",
    "                    propriedades.extend(matches)\n",
    "            \n",
    "            # Armazenar resultados\n",
    "            df_result.iloc[idx, df_result.columns.get_loc('nano_relevance_score')] = analise.get('nano_relevance_score', 0)\n",
    "            df_result.iloc[idx, df_result.columns.get_loc('functional_relevance_score')] = analise.get('functional_relevance_score', 0)\n",
    "            df_result.iloc[idx, df_result.columns.get_loc('total_matches')] = analise.get('total_matches', 0)\n",
    "            df_result.iloc[idx, df_result.columns.get_loc('nanomateriais_encontrados')] = json.dumps(list(set(nanomateriais)), ensure_ascii=False)\n",
    "            df_result.iloc[idx, df_result.columns.get_loc('propriedades_funcionais')] = json.dumps(list(set(propriedades)), ensure_ascii=False)\n",
    "            df_result.iloc[idx, df_result.columns.get_loc('metodos_sintese')] = json.dumps(patterns_found.get('sintese', []), ensure_ascii=False)\n",
    "            df_result.iloc[idx, df_result.columns.get_loc('medidas_encontradas')] = json.dumps(patterns_found.get('medidas', []), ensure_ascii=False)\n",
    "            df_result.iloc[idx, df_result.columns.get_loc('analise_completa')] = json.dumps(analise, ensure_ascii=False)\n",
    "        \n",
    "        # Progresso\n",
    "        progress = ((batch_idx + 1) / total_batches) * 100\n",
    "        print(f\"âœ… Lote concluÃ­do ({progress:.1f}% total)\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ ANÃLISE REGEX CONCLUÃDA\")\n",
    "    print(f\"ğŸ“Š Registros processados: {total_records:,}\")\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "# Executar anÃ¡lise em lote usando dados filtrados por Open Access\n",
    "print(\"ğŸš€ Iniciando anÃ¡lise regex do dataset filtrado...\")\n",
    "# Usar df_clean que contÃ©m os dados filtrados por Open Access\n",
    "df_analyzed = analyze_dataset_regex(df_clean, regex_analyzer, batch_size=50)\n",
    "print(\"âœ… AnÃ¡lise regex concluÃ­da\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e56cc",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ EstatÃ­sticas e AnÃ¡lise dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dd3ffc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ GERANDO ESTATÃSTICAS DA ANÃLISE REGEX\n",
      "=============================================\n",
      "ğŸ“Š Registros com nanomateriais: 4,235 (46.8%)\n",
      "ğŸ“Š Registros com propriedades funcionais: 8,071 (89.2%)\n",
      "\\nğŸ” Analisando frequÃªncias...\n",
      "\n",
      "ğŸ† TOP 10 NANOMATERIAIS:\n",
      "   tio2: 550 menÃ§Ãµes\n",
      "   al2o3: 446 menÃ§Ãµes\n",
      "   sio2: 383 menÃ§Ãµes\n",
      "   silica: 382 menÃ§Ãµes\n",
      "   graphene: 334 menÃ§Ãµes\n",
      "   alumina: 314 menÃ§Ãµes\n",
      "   nanocomposite: 296 menÃ§Ãµes\n",
      "   zno: 264 menÃ§Ãµes\n",
      "   silver: 259 menÃ§Ãµes\n",
      "   zirconia: 256 menÃ§Ãµes\n",
      "\n",
      "ğŸ† TOP 10 PROPRIEDADES FUNCIONAIS:\n",
      "   coating: 6,062 menÃ§Ãµes\n",
      "   coatings: 3,628 menÃ§Ãµes\n",
      "   thin films: 602 menÃ§Ãµes\n",
      "   sol-gel: 424 menÃ§Ãµes\n",
      "   thermal barrier: 311 menÃ§Ãµes\n",
      "   thin film: 296 menÃ§Ãµes\n",
      "   biomedical: 274 menÃ§Ãµes\n",
      "   spin coating: 244 menÃ§Ãµes\n",
      "   superhydrophobic: 233 menÃ§Ãµes\n",
      "   magnetic: 232 menÃ§Ãµes\n",
      "\n",
      "ğŸ† TOP 10 MÃ‰TODOS DE SÃNTESE:\n",
      "   electrochemical: 862 menÃ§Ãµes\n",
      "   sol-gel: 424 menÃ§Ãµes\n",
      "   chemical vapor deposition: 164 menÃ§Ãµes\n",
      "   hydrothermal: 134 menÃ§Ãµes\n",
      "   precipitation: 127 menÃ§Ãµes\n",
      "   pvd: 107 menÃ§Ãµes\n",
      "   cvd: 105 menÃ§Ãµes\n",
      "   physical vapor deposition: 80 menÃ§Ãµes\n",
      "   co-precipitation: 36 menÃ§Ãµes\n",
      "   ball milling: 31 menÃ§Ãµes\n",
      "\n",
      "âœ… EstatÃ­sticas geradas com sucesso\n",
      "\n",
      "ğŸ† TOP 10 NANOMATERIAIS:\n",
      "   tio2: 550 menÃ§Ãµes\n",
      "   al2o3: 446 menÃ§Ãµes\n",
      "   sio2: 383 menÃ§Ãµes\n",
      "   silica: 382 menÃ§Ãµes\n",
      "   graphene: 334 menÃ§Ãµes\n",
      "   alumina: 314 menÃ§Ãµes\n",
      "   nanocomposite: 296 menÃ§Ãµes\n",
      "   zno: 264 menÃ§Ãµes\n",
      "   silver: 259 menÃ§Ãµes\n",
      "   zirconia: 256 menÃ§Ãµes\n",
      "\n",
      "ğŸ† TOP 10 PROPRIEDADES FUNCIONAIS:\n",
      "   coating: 6,062 menÃ§Ãµes\n",
      "   coatings: 3,628 menÃ§Ãµes\n",
      "   thin films: 602 menÃ§Ãµes\n",
      "   sol-gel: 424 menÃ§Ãµes\n",
      "   thermal barrier: 311 menÃ§Ãµes\n",
      "   thin film: 296 menÃ§Ãµes\n",
      "   biomedical: 274 menÃ§Ãµes\n",
      "   spin coating: 244 menÃ§Ãµes\n",
      "   superhydrophobic: 233 menÃ§Ãµes\n",
      "   magnetic: 232 menÃ§Ãµes\n",
      "\n",
      "ğŸ† TOP 10 MÃ‰TODOS DE SÃNTESE:\n",
      "   electrochemical: 862 menÃ§Ãµes\n",
      "   sol-gel: 424 menÃ§Ãµes\n",
      "   chemical vapor deposition: 164 menÃ§Ãµes\n",
      "   hydrothermal: 134 menÃ§Ãµes\n",
      "   precipitation: 127 menÃ§Ãµes\n",
      "   pvd: 107 menÃ§Ãµes\n",
      "   cvd: 105 menÃ§Ãµes\n",
      "   physical vapor deposition: 80 menÃ§Ãµes\n",
      "   co-precipitation: 36 menÃ§Ãµes\n",
      "   ball milling: 31 menÃ§Ãµes\n",
      "\n",
      "âœ… EstatÃ­sticas geradas com sucesso\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ˆ EstatÃ­sticas e anÃ¡lise dos resultados\n",
    "\n",
    "def generate_regex_statistics(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"Gera estatÃ­sticas abrangentes da anÃ¡lise regex\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“ˆ GERANDO ESTATÃSTICAS DA ANÃLISE REGEX\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    stats = {\n",
    "        'total_registros': len(df),\n",
    "        'registros_com_nano': 0,\n",
    "        'registros_com_func': 0,\n",
    "        'scores': {},\n",
    "        'nanomateriais_frequencia': Counter(),\n",
    "        'propriedades_frequencia': Counter(),\n",
    "        'metodos_sintese_frequencia': Counter(),\n",
    "        'coocorrencias': defaultdict(int)\n",
    "    }\n",
    "    \n",
    "    # AnÃ¡lise de scores\n",
    "    if 'nano_relevance_score' in df.columns:\n",
    "        nano_scores = pd.to_numeric(df['nano_relevance_score'], errors='coerce').fillna(0)\n",
    "        stats['registros_com_nano'] = (nano_scores > 0).sum()\n",
    "        stats['scores']['nano'] = {\n",
    "            'mean': float(nano_scores.mean()),\n",
    "            'median': float(nano_scores.median()),\n",
    "            'max': float(nano_scores.max()),\n",
    "            'std': float(nano_scores.std())\n",
    "        }\n",
    "    \n",
    "    if 'functional_relevance_score' in df.columns:\n",
    "        func_scores = pd.to_numeric(df['functional_relevance_score'], errors='coerce').fillna(0)\n",
    "        stats['registros_com_func'] = (func_scores > 0).sum()\n",
    "        stats['scores']['functional'] = {\n",
    "            'mean': float(func_scores.mean()),\n",
    "            'median': float(func_scores.median()),\n",
    "            'max': float(func_scores.max()),\n",
    "            'std': float(func_scores.std())\n",
    "        }\n",
    "    \n",
    "    print(f\"ğŸ“Š Registros com nanomateriais: {stats['registros_com_nano']:,} ({stats['registros_com_nano']/len(df)*100:.1f}%)\")\n",
    "    print(f\"ğŸ“Š Registros com propriedades funcionais: {stats['registros_com_func']:,} ({stats['registros_com_func']/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # AnÃ¡lise de frequÃªncias\n",
    "    print(f\"\\\\nğŸ” Analisando frequÃªncias...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Nanomateriais\n",
    "        if pd.notna(row.get('nanomateriais_encontrados')):\n",
    "            try:\n",
    "                nanomateriais = json.loads(row['nanomateriais_encontrados'])\n",
    "                for nano in nanomateriais:\n",
    "                    stats['nanomateriais_frequencia'][nano] += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Propriedades funcionais\n",
    "        if pd.notna(row.get('propriedades_funcionais')):\n",
    "            try:\n",
    "                propriedades = json.loads(row['propriedades_funcionais'])\n",
    "                for prop in propriedades:\n",
    "                    stats['propriedades_frequencia'][prop] += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # MÃ©todos de sÃ­ntese\n",
    "        if pd.notna(row.get('metodos_sintese')):\n",
    "            try:\n",
    "                metodos = json.loads(row['metodos_sintese'])\n",
    "                for metodo in metodos:\n",
    "                    stats['metodos_sintese_frequencia'][metodo] += 1\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Top 10 de cada categoria\n",
    "    print(f\"\\nğŸ† TOP 10 NANOMATERIAIS:\")\n",
    "    for material, freq in stats['nanomateriais_frequencia'].most_common(10):\n",
    "        print(f\"   {material}: {freq:,} menÃ§Ãµes\")\n",
    "    \n",
    "    print(f\"\\nğŸ† TOP 10 PROPRIEDADES FUNCIONAIS:\")\n",
    "    for prop, freq in stats['propriedades_frequencia'].most_common(10):\n",
    "        print(f\"   {prop}: {freq:,} menÃ§Ãµes\")\n",
    "    \n",
    "    print(f\"\\nğŸ† TOP 10 MÃ‰TODOS DE SÃNTESE:\")\n",
    "    for metodo, freq in stats['metodos_sintese_frequencia'].most_common(10):\n",
    "        print(f\"   {metodo}: {freq:,} menÃ§Ãµes\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Gerar estatÃ­sticas\n",
    "regex_stats = generate_regex_statistics(df_analyzed)\n",
    "print(\"\\nâœ… EstatÃ­sticas geradas com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec41d71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— ANALISANDO CO-OCORRÃŠNCIAS\n",
      "==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ† TOP 20 CO-OCORRÃŠNCIAS:\n",
      "   tio2 + coating: 387 registros\n",
      "   al2o3 + coating: 324 registros\n",
      "   silica + coating: 282 registros\n",
      "   sio2 + coating: 279 registros\n",
      "   graphene + coating: 256 registros\n",
      "   tio2 + coatings: 239 registros\n",
      "   al2o3 + coatings: 238 registros\n",
      "   alumina + coating: 216 registros\n",
      "   nanocomposite + coating: 213 registros\n",
      "   zno + coating: 203 registros\n",
      "   zirconia + coating: 182 registros\n",
      "   epoxy + coating: 176 registros\n",
      "   silver + coating: 174 registros\n",
      "   sio2 + coatings: 166 registros\n",
      "   zirconia + coatings: 164 registros\n",
      "   alumina + coatings: 160 registros\n",
      "   silica + coatings: 158 registros\n",
      "   hydroxyapatite + coating: 149 registros\n",
      "   nanocomposite + coatings: 143 registros\n",
      "   tio2 + photocatalytic: 142 registros\n",
      "ğŸ¯ IDENTIFICANDO REGISTROS DE ALTA RELEVÃ‚NCIA\n",
      "==================================================\n",
      "ğŸ“Š Registros com alta relevÃ¢ncia nano (â‰¥10.0): 1,168\n",
      "ğŸ“Š Registros com alta relevÃ¢ncia funcional (â‰¥5.0): 6,529\n",
      "ğŸ¯ Registros com AMBAS as relevÃ¢ncias altas: 1,006\n",
      "\n",
      "ğŸ“ˆ DISTRIBUIÃ‡ÃƒO POR CATEGORIA:\n",
      "   high_functional: 5,523 (61.1%)\n",
      "   low: 2,355 (26.0%)\n",
      "   high_both: 1,006 (11.1%)\n",
      "   high_nano: 162 (1.8%)\n",
      "\n",
      "âœ… IdentificaÃ§Ã£o de registros de alta relevÃ¢ncia concluÃ­da\n",
      "\n",
      "âœ… IdentificaÃ§Ã£o de registros de alta relevÃ¢ncia concluÃ­da\n"
     ]
    }
   ],
   "source": [
    "def analyze_cooccurrences(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"Analisa co-ocorrÃªncias entre nanomateriais e propriedades funcionais\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”— ANALISANDO CO-OCORRÃŠNCIAS\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    cooccurrences = defaultdict(int)\n",
    "    material_property_pairs = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Extrair nanomateriais e propriedades\n",
    "        nanomateriais = []\n",
    "        propriedades = []\n",
    "        \n",
    "        if pd.notna(row.get('nanomateriais_encontrados')):\n",
    "            try:\n",
    "                nanomateriais = json.loads(row['nanomateriais_encontrados'])\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if pd.notna(row.get('propriedades_funcionais')):\n",
    "            try:\n",
    "                propriedades = json.loads(row['propriedades_funcionais'])\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Calcular co-ocorrÃªncias\n",
    "        for nano in nanomateriais:\n",
    "            for prop in propriedades:\n",
    "                pair = f\"{nano} + {prop}\"\n",
    "                cooccurrences[pair] += 1\n",
    "                material_property_pairs.append((nano, prop))\n",
    "    \n",
    "    # Top 20 co-ocorrÃªncias\n",
    "    print(f\"\\nğŸ† TOP 20 CO-OCORRÃŠNCIAS:\")\n",
    "    for pair, count in Counter(cooccurrences).most_common(20):\n",
    "        print(f\"   {pair}: {count} registros\")\n",
    "    \n",
    "    return {\n",
    "        'cooccurrences': dict(cooccurrences),\n",
    "        'total_pairs': len(material_property_pairs),\n",
    "        'unique_pairs': len(set(material_property_pairs))\n",
    "    }\n",
    "\n",
    "def identify_high_relevance_records(df: pd.DataFrame, \n",
    "                                  nano_threshold: float = 10.0,\n",
    "                                  func_threshold: float = 5.0) -> pd.DataFrame:\n",
    "    \"\"\"Identifica registros com alta relevÃ¢ncia para nanotecnologia de tintas\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ¯ IDENTIFICANDO REGISTROS DE ALTA RELEVÃ‚NCIA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Filtros de relevÃ¢ncia\n",
    "    nano_scores = pd.to_numeric(df.get('nano_relevance_score', 0), errors='coerce').fillna(0)\n",
    "    func_scores = pd.to_numeric(df.get('functional_relevance_score', 0), errors='coerce').fillna(0)\n",
    "    \n",
    "    # Diferentes nÃ­veis de relevÃ¢ncia\n",
    "    high_nano = df[nano_scores >= nano_threshold]\n",
    "    high_func = df[func_scores >= func_threshold]\n",
    "    high_both = df[(nano_scores >= nano_threshold) & (func_scores >= func_threshold)]\n",
    "    \n",
    "    print(f\"ğŸ“Š Registros com alta relevÃ¢ncia nano (â‰¥{nano_threshold}): {len(high_nano):,}\")\n",
    "    print(f\"ğŸ“Š Registros com alta relevÃ¢ncia funcional (â‰¥{func_threshold}): {len(high_func):,}\")\n",
    "    print(f\"ğŸ¯ Registros com AMBAS as relevÃ¢ncias altas: {len(high_both):,}\")\n",
    "    \n",
    "    # Adicionar classificaÃ§Ã£o de relevÃ¢ncia\n",
    "    df_result = df.copy()\n",
    "    df_result['relevance_category'] = 'low'\n",
    "    \n",
    "    df_result.loc[nano_scores >= nano_threshold, 'relevance_category'] = 'high_nano'\n",
    "    df_result.loc[func_scores >= func_threshold, 'relevance_category'] = 'high_functional'\n",
    "    df_result.loc[(nano_scores >= nano_threshold) & (func_scores >= func_threshold), 'relevance_category'] = 'high_both'\n",
    "    \n",
    "    # EstatÃ­sticas por categoria\n",
    "    category_counts = df_result['relevance_category'].value_counts()\n",
    "    print(\"\\nğŸ“ˆ DISTRIBUIÃ‡ÃƒO POR CATEGORIA:\")\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / len(df_result)) * 100\n",
    "        print(f\"   {category}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "# Analisar co-ocorrÃªncias\n",
    "cooccurrence_analysis = analyze_cooccurrences(df_analyzed)\n",
    "\n",
    "# Identificar registros de alta relevÃ¢ncia\n",
    "df_with_relevance = identify_high_relevance_records(df_analyzed)\n",
    "print(\"\\nâœ… IdentificaÃ§Ã£o de registros de alta relevÃ¢ncia concluÃ­da\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e73ce",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Salvamento dos Resultados da AnÃ¡lise Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9c413ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ SALVANDO RESULTADOS DA ANÃLISE REGEX\n",
      "========================================\n",
      "âœ… Dataset salvo: /home/delon/Modelos/modeloCenanoInk/data/processed/dataset_with_regex_analysis.csv\n",
      "âœ… Dataset salvo: /home/delon/Modelos/modeloCenanoInk/data/processed/dataset_with_regex_analysis.csv\n",
      "âœ… Registros de alta relevÃ¢ncia salvos: /home/delon/Modelos/modeloCenanoInk/data/processed/high_relevance_records.csv\n",
      "âœ… EstatÃ­sticas salvas: /home/delon/Modelos/modeloCenanoInk/data/processed/regex_analysis_statistics.json\n",
      "âœ… Co-ocorrÃªncias salvas: /home/delon/Modelos/modeloCenanoInk/data/processed/cooccurrence_analysis.json\n",
      "âœ… Resumo salvo: /home/delon/Modelos/modeloCenanoInk/data/processed/regex_analysis_summary.json\n",
      "\n",
      "ğŸ‰ ANÃLISE REGEX CONCLUÃDA COM SUCESSO!\n",
      "ğŸ“Š Total de registros processados: 9,046\n",
      "ğŸ¯ Registros de alta relevÃ¢ncia: 6,691\n",
      "ğŸ’¾ Arquivos gerados: 5\n",
      "\n",
      "ğŸ“ Arquivos salvos:\n",
      "   dataset: /home/delon/Modelos/modeloCenanoInk/data/processed/dataset_with_regex_analysis.csv\n",
      "   high_relevance: /home/delon/Modelos/modeloCenanoInk/data/processed/high_relevance_records.csv\n",
      "   statistics: /home/delon/Modelos/modeloCenanoInk/data/processed/regex_analysis_statistics.json\n",
      "   cooccurrences: /home/delon/Modelos/modeloCenanoInk/data/processed/cooccurrence_analysis.json\n",
      "   summary: /home/delon/Modelos/modeloCenanoInk/data/processed/regex_analysis_summary.json\n",
      "âœ… Registros de alta relevÃ¢ncia salvos: /home/delon/Modelos/modeloCenanoInk/data/processed/high_relevance_records.csv\n",
      "âœ… EstatÃ­sticas salvas: /home/delon/Modelos/modeloCenanoInk/data/processed/regex_analysis_statistics.json\n",
      "âœ… Co-ocorrÃªncias salvas: /home/delon/Modelos/modeloCenanoInk/data/processed/cooccurrence_analysis.json\n",
      "âœ… Resumo salvo: /home/delon/Modelos/modeloCenanoInk/data/processed/regex_analysis_summary.json\n",
      "\n",
      "ğŸ‰ ANÃLISE REGEX CONCLUÃDA COM SUCESSO!\n",
      "ğŸ“Š Total de registros processados: 9,046\n",
      "ğŸ¯ Registros de alta relevÃ¢ncia: 6,691\n",
      "ğŸ’¾ Arquivos gerados: 5\n",
      "\n",
      "ğŸ“ Arquivos salvos:\n",
      "   dataset: /home/delon/Modelos/modeloCenanoInk/data/processed/dataset_with_regex_analysis.csv\n",
      "   high_relevance: /home/delon/Modelos/modeloCenanoInk/data/processed/high_relevance_records.csv\n",
      "   statistics: /home/delon/Modelos/modeloCenanoInk/data/processed/regex_analysis_statistics.json\n",
      "   cooccurrences: /home/delon/Modelos/modeloCenanoInk/data/processed/cooccurrence_analysis.json\n",
      "   summary: /home/delon/Modelos/modeloCenanoInk/data/processed/regex_analysis_summary.json\n"
     ]
    }
   ],
   "source": [
    "def save_regex_results(df: pd.DataFrame, stats: Dict, cooccurrences: Dict) -> Dict[str, str]:\n",
    "    \"\"\"Salva todos os resultados da anÃ¡lise regex\"\"\"\n",
    "    \n",
    "    print(\"ğŸ’¾ SALVANDO RESULTADOS DA ANÃLISE REGEX\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Criar diretÃ³rio se nÃ£o existir\n",
    "    processed_dir = PATHS.get('processed', './processed/')\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    # Caminhos dos arquivos\n",
    "    files_saved = {}\n",
    "    \n",
    "    # 1. Dataset com anÃ¡lise regex\n",
    "    dataset_path = os.path.join(processed_dir, 'dataset_with_regex_analysis.csv')\n",
    "    df.to_csv(dataset_path, index=False, encoding='utf-8-sig')\n",
    "    files_saved['dataset'] = dataset_path\n",
    "    print(f\"âœ… Dataset salvo: {dataset_path}\")\n",
    "    \n",
    "    # 2. Registros de alta relevÃ¢ncia\n",
    "    high_relevance = df[df['relevance_category'].isin(['high_nano', 'high_functional', 'high_both'])]\n",
    "    high_relevance_path = os.path.join(processed_dir, 'high_relevance_records.csv')\n",
    "    high_relevance.to_csv(high_relevance_path, index=False, encoding='utf-8-sig')\n",
    "    files_saved['high_relevance'] = high_relevance_path\n",
    "    print(f\"âœ… Registros de alta relevÃ¢ncia salvos: {high_relevance_path}\")\n",
    "    \n",
    "    # 3. EstatÃ­sticas da anÃ¡lise\n",
    "    stats_path = os.path.join(processed_dir, 'regex_analysis_statistics.json')\n",
    "    with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(stats, f, ensure_ascii=False, indent=2, default=str)\n",
    "    files_saved['statistics'] = stats_path\n",
    "    print(f\"âœ… EstatÃ­sticas salvas: {stats_path}\")\n",
    "    \n",
    "    # 4. AnÃ¡lise de co-ocorrÃªncias\n",
    "    cooccurrence_path = os.path.join(processed_dir, 'cooccurrence_analysis.json')\n",
    "    with open(cooccurrence_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cooccurrences, f, ensure_ascii=False, indent=2, default=str)\n",
    "    files_saved['cooccurrences'] = cooccurrence_path\n",
    "    print(f\"âœ… Co-ocorrÃªncias salvas: {cooccurrence_path}\")\n",
    "    \n",
    "    # 5. Resumo da anÃ¡lise\n",
    "    summary = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'notebook': '03_analise_regex.ipynb',\n",
    "        'total_records': len(df),\n",
    "        'high_relevance_records': len(high_relevance),\n",
    "        'nanomaterials_found': len(stats['nanomateriais_frequencia']),\n",
    "        'functional_properties_found': len(stats['propriedades_frequencia']),\n",
    "        'synthesis_methods_found': len(stats['metodos_sintese_frequencia']),\n",
    "        'files_generated': files_saved,\n",
    "        'next_notebook': '04_analise_gemini.ipynb'\n",
    "    }\n",
    "    \n",
    "    summary_path = os.path.join(processed_dir, 'regex_analysis_summary.json')\n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "    files_saved['summary'] = summary_path\n",
    "    print(f\"âœ… Resumo salvo: {summary_path}\")\n",
    "    \n",
    "    return files_saved\n",
    "\n",
    "# Salvar todos os resultados\n",
    "saved_files = save_regex_results(df_with_relevance, regex_stats, cooccurrence_analysis)\n",
    "\n",
    "print(f\"\\nğŸ‰ ANÃLISE REGEX CONCLUÃDA COM SUCESSO!\")\n",
    "print(f\"ğŸ“Š Total de registros processados: {len(df_with_relevance):,}\")\n",
    "print(f\"ğŸ¯ Registros de alta relevÃ¢ncia: {len(df_with_relevance[df_with_relevance['relevance_category'] != 'low']):,}\")\n",
    "print(f\"ğŸ’¾ Arquivos gerados: {len(saved_files)}\")\n",
    "print(f\"\\nğŸ“ Arquivos salvos:\")\n",
    "for desc, path in saved_files.items():\n",
    "    print(f\"   {desc}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57a7435a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š RelatÃ³rio da AnÃ¡lise Regex:\n",
      "  Total de artigos analisados: 9,046\n",
      "  DistribuiÃ§Ã£o por categoria de relevÃ¢ncia:\n",
      "    high_functional: 5,523 artigos\n",
      "    low: 2,355 artigos\n",
      "    high_both: 1,006 artigos\n",
      "    high_nano: 162 artigos\n",
      "  EstatÃ­sticas de nanomateriais:\n",
      "    Artigos com nanomateriais: 4,235\n",
      "    Score mÃ©dio: 3.94\n",
      "  Top nanomateriais encontrados:\n",
      "    tio2: 550\n",
      "    al2o3: 446\n",
      "    sio2: 383\n",
      "    silica: 382\n",
      "    graphene: 334\n",
      "ğŸ’¾ RelatÃ³rio salvo em '/home/delon/Modelos/modeloCenanoInk/data/processed/relatorio_analise_regex.json'\n"
     ]
    }
   ],
   "source": [
    "def gerar_relatorio_regex(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Gera relatÃ³rio detalhado da anÃ¡lise regex.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame com anÃ¡lise regex\n",
    "    \n",
    "    Returns:\n",
    "        DicionÃ¡rio com estatÃ­sticas\n",
    "    \"\"\"\n",
    "    def convert_numpy_types(obj):\n",
    "        \"\"\"Converte tipos NumPy para tipos Python nativos para serializaÃ§Ã£o JSON\"\"\"\n",
    "        if hasattr(obj, 'item'):\n",
    "            return obj.item()\n",
    "        elif hasattr(obj, 'tolist'):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: convert_numpy_types(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_numpy_types(v) for v in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    if df.empty:\n",
    "        return {}\n",
    "    \n",
    "    # Usar as colunas corretas baseadas na anÃ¡lise atual\n",
    "    relatorio = {\n",
    "        'total_artigos_analisados': int(len(df)),\n",
    "        'distribuicao_escopo': convert_numpy_types(df['relevance_category'].value_counts().to_dict() if 'relevance_category' in df.columns else {}),\n",
    "        'estatisticas_nanomateriais': {\n",
    "            'media_score': float(df['nano_relevance_score'].mean() if 'nano_relevance_score' in df.columns else 0),\n",
    "            'mediana_score': float(df['nano_relevance_score'].median() if 'nano_relevance_score' in df.columns else 0),\n",
    "            'max_score': float(df['nano_relevance_score'].max() if 'nano_relevance_score' in df.columns else 0),\n",
    "            'artigos_com_nanomateriais': int((df['nano_relevance_score'] > 0).sum() if 'nano_relevance_score' in df.columns else 0)\n",
    "        },\n",
    "        'estatisticas_funcionais': {\n",
    "            'media_score': float(df['functional_relevance_score'].mean() if 'functional_relevance_score' in df.columns else 0),\n",
    "            'mediana_score': float(df['functional_relevance_score'].median() if 'functional_relevance_score' in df.columns else 0),\n",
    "            'max_score': float(df['functional_relevance_score'].max() if 'functional_relevance_score' in df.columns else 0),\n",
    "            'artigos_com_funcionais': int((df['functional_relevance_score'] > 0).sum() if 'functional_relevance_score' in df.columns else 0)\n",
    "        },\n",
    "        'top_nanomateriais': {},\n",
    "        'top_propriedades_funcionais': {}\n",
    "    }\n",
    "    \n",
    "    # Extrair nanomateriais mais frequentes\n",
    "    if 'nanomateriais_encontrados' in df.columns:\n",
    "        todos_nanomateriais = []\n",
    "        for nanomateriais_json in df['nanomateriais_encontrados'].dropna():\n",
    "            try:\n",
    "                nanomateriais = json.loads(nanomateriais_json)\n",
    "                todos_nanomateriais.extend(nanomateriais)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if todos_nanomateriais:\n",
    "            contador_nanomateriais = Counter(todos_nanomateriais)\n",
    "            relatorio['top_nanomateriais'] = dict(contador_nanomateriais.most_common(10))\n",
    "    \n",
    "    # Extrair propriedades funcionais mais frequentes\n",
    "    if 'propriedades_funcionais' in df.columns:\n",
    "        todas_propriedades = []\n",
    "        for propriedades_json in df['propriedades_funcionais'].dropna():\n",
    "            try:\n",
    "                propriedades = json.loads(propriedades_json)\n",
    "                todas_propriedades.extend(propriedades)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if todas_propriedades:\n",
    "            contador_propriedades = Counter(todas_propriedades)\n",
    "            relatorio['top_propriedades_funcionais'] = dict(contador_propriedades.most_common(10))\n",
    "    \n",
    "    return relatorio\n",
    "\n",
    "# Gerar relatÃ³rio usando os dados corretos\n",
    "if not df_with_relevance.empty:\n",
    "    relatorio_regex = gerar_relatorio_regex(df_with_relevance)\n",
    "    \n",
    "    # Criar diretÃ³rio se nÃ£o existir\n",
    "    processed_dir = PATHS.get('processed', './processed/')\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    # Salvar relatÃ³rio\n",
    "    relatorio_path = os.path.join(processed_dir, 'relatorio_analise_regex.json')\n",
    "    with open(relatorio_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(relatorio_regex, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"ğŸ“Š RelatÃ³rio da AnÃ¡lise Regex:\")\n",
    "    print(f\"  Total de artigos analisados: {relatorio_regex['total_artigos_analisados']:,}\")\n",
    "    print(\"  DistribuiÃ§Ã£o por categoria de relevÃ¢ncia:\")\n",
    "    for categoria, count in relatorio_regex['distribuicao_escopo'].items():\n",
    "        print(f\"    {categoria}: {count:,} artigos\")\n",
    "    \n",
    "    print(\"  EstatÃ­sticas de nanomateriais:\")\n",
    "    stats_nano = relatorio_regex['estatisticas_nanomateriais']\n",
    "    print(f\"    Artigos com nanomateriais: {stats_nano['artigos_com_nanomateriais']:,}\")\n",
    "    print(f\"    Score mÃ©dio: {stats_nano['media_score']:.2f}\")\n",
    "    \n",
    "    print(\"  Top nanomateriais encontrados:\")\n",
    "    for nanomaterial, count in list(relatorio_regex['top_nanomateriais'].items())[:5]:\n",
    "        print(f\"    {nanomaterial}: {count:,}\")\n",
    "    \n",
    "    print(f\"ğŸ’¾ RelatÃ³rio salvo em '{relatorio_path}'\")\n",
    "else:\n",
    "    print(\"âš ï¸  Dados nÃ£o disponÃ­veis para relatÃ³rio\")\n",
    "    relatorio_regex = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b320ff",
   "metadata": {},
   "source": [
    "## ğŸ”„ PreparaÃ§Ã£o para PrÃ³xima Etapa (AnÃ¡lise Gemini)\n",
    "\n",
    "# Verificar se o sistema estÃ¡ pronto para a prÃ³xima etapa\n",
    "ready_for_gemini = True\n",
    "ready_checks = []\n",
    "\n",
    "# Verificar arquivos necessÃ¡rios\n",
    "required_files = [\n",
    "    'dataset_with_regex_analysis.csv',\n",
    "    'high_relevance_records.csv', \n",
    "    'regex_analysis_statistics.json'\n",
    "]\n",
    "\n",
    "processed_dir = PATHS.get('processed', './processed/')\n",
    "for filename in required_files:\n",
    "    filepath = os.path.join(processed_dir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        ready_checks.append(f\"âœ… {filename}\")\n",
    "    else:\n",
    "        ready_checks.append(f\"âŒ {filename}\")\n",
    "        ready_for_gemini = False\n",
    "\n",
    "# Verificar configuraÃ§Ã£o da API Gemini\n",
    "if CONFIG.get('gemini', {}).get('api_key'):\n",
    "    ready_checks.append(\"âœ… API Gemini configurada\")\n",
    "else:\n",
    "    ready_checks.append(\"âŒ API Gemini nÃ£o configurada\")\n",
    "    ready_for_gemini = False\n",
    "\n",
    "# Atualizar configuraÃ§Ã£o do sistema\n",
    "config_data['regex_analysis'] = {\n",
    "    'completed': True,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'records_processed': len(df_with_relevance),\n",
    "    'high_relevance_records': len(df_with_relevance[df_with_relevance['relevance_category'] != 'low']),\n",
    "    'files_generated': list(saved_files.keys()),\n",
    "    'ready_for_gemini': ready_for_gemini\n",
    "}\n",
    "\n",
    "# Salvar configuraÃ§Ã£o atualizada\n",
    "with open('config_sistema.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(config_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"ğŸ”„ PREPARAÃ‡ÃƒO PARA PRÃ“XIMA ETAPA\")\n",
    "print(\"=\" * 35)\n",
    "print(\"\\nğŸ“‹ VerificaÃ§Ãµes:\")\n",
    "for check in ready_checks:\n",
    "    print(f\"   {check}\")\n",
    "\n",
    "if ready_for_gemini:\n",
    "    print(\"\\nâœ… SISTEMA PRONTO PARA ANÃLISE GEMINI!\")\n",
    "    print(\"ğŸš€ PrÃ³ximo notebook: 04_analise_gemini.ipynb\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Sistema nÃ£o estÃ¡ completamente pronto para anÃ¡lise Gemini\")\n",
    "    print(\"ğŸ’¡ Verifique as configuraÃ§Ãµes e arquivos faltantes acima\")\n",
    "\n",
    "print(f\"\\nğŸ“Š RESUMO FINAL:\")\n",
    "print(f\"   ğŸ“ Registros processados: {len(df_with_relevance):,}\")\n",
    "print(f\"   ğŸ¯ Alta relevÃ¢ncia nano: {len(df_with_relevance[df_with_relevance['relevance_category'].isin(['high_nano', 'high_both'])]):,}\")\n",
    "print(f\"   ğŸ”§ Alta relevÃ¢ncia funcional: {len(df_with_relevance[df_with_relevance['relevance_category'].isin(['high_functional', 'high_both'])]):,}\")\n",
    "print(f\"   â­ Ambas relevÃ¢ncias altas: {len(df_with_relevance[df_with_relevance['relevance_category'] == 'high_both']):,}\")\n",
    "print(f\"   ğŸ§ª Nanomateriais Ãºnicos: {len(regex_stats['nanomateriais_frequencia'])}\")\n",
    "print(f\"   âš™ï¸ Propriedades funcionais Ãºnicas: {len(regex_stats['propriedades_frequencia'])}\")\n",
    "\n",
    "print(\"\\nğŸ‰ NOTEBOOK 03 - ANÃLISE REGEX CONCLUÃDO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b18867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Notebook 03 - AnÃ¡lise Regex concluÃ­do\n",
      "ğŸ“Š 9,046 artigos processados com anÃ¡lise regex\n",
      "ğŸ”„ PrÃ³xima etapa: 04_analise_gemini.ipynb\n",
      "ğŸ’¾ Metadados salvos em '/home/delon/Modelos/modeloCenanoInk/data/processed/metadados_analise_regex.json'\n",
      "\n",
      "ğŸ¯ RESUMO FINAL DA ANÃLISE:\n",
      "   ğŸ“ Total de registros: 9,046\n",
      "   high_functional: 5,523 registros\n",
      "   low: 2,355 registros\n",
      "   high_both: 1,006 registros\n",
      "   high_nano: 162 registros\n",
      "   ğŸ§ª Nanomateriais Ãºnicos: 92\n",
      "   âš™ï¸ Propriedades funcionais Ãºnicas: 50\n"
     ]
    }
   ],
   "source": [
    "# Atualizar metadados para prÃ³xima etapa\n",
    "metadados_regex = {\n",
    "    'notebook': '03_analise_regex',\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'dados_processados': os.path.join(PATHS.get('processed', './processed/'), 'dataset_with_regex_analysis.csv'),\n",
    "    'relatorio': os.path.join(PATHS.get('processed', './processed/'), 'relatorio_analise_regex.json'),\n",
    "    'total_artigos': len(df_with_relevance) if 'df_with_relevance' in locals() and not df_with_relevance.empty else 0,\n",
    "    'colunas_adicionadas': [\n",
    "        'nano_relevance_score',\n",
    "        'functional_relevance_score',\n",
    "        'total_matches',\n",
    "        'nanomateriais_encontrados',\n",
    "        'propriedades_funcionais',\n",
    "        'metodos_sintese',\n",
    "        'medidas_encontradas',\n",
    "        'analise_completa',\n",
    "        'relevance_category'\n",
    "    ],\n",
    "    'proxima_etapa': '04_analise_gemini.ipynb'\n",
    "}\n",
    "\n",
    "# Salvar metadados\n",
    "metadados_path = os.path.join(PATHS.get('processed', './processed/'), 'metadados_analise_regex.json')\n",
    "with open(metadados_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadados_regex, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… Notebook 03 - AnÃ¡lise Regex concluÃ­do\")\n",
    "print(f\"ğŸ“Š {metadados_regex['total_artigos']:,} artigos processados com anÃ¡lise regex\")\n",
    "print(\"ğŸ”„ PrÃ³xima etapa: 04_analise_gemini.ipynb\")\n",
    "print(f\"ğŸ’¾ Metadados salvos em '{metadados_path}'\")\n",
    "\n",
    "# Exibir resumo final\n",
    "if 'df_with_relevance' in locals() and not df_with_relevance.empty:\n",
    "    print(\"\\nğŸ¯ RESUMO FINAL DA ANÃLISE:\")\n",
    "    print(f\"   ğŸ“ Total de registros: {len(df_with_relevance):,}\")\n",
    "    if 'relevance_category' in df_with_relevance.columns:\n",
    "        category_counts = df_with_relevance['relevance_category'].value_counts()\n",
    "        for category, count in category_counts.items():\n",
    "            print(f\"   {category}: {count:,} registros\")\n",
    "    print(f\"   ğŸ§ª Nanomateriais Ãºnicos: {len(regex_stats['nanomateriais_frequencia']) if 'regex_stats' in locals() else 0}\")\n",
    "    print(f\"   âš™ï¸ Propriedades funcionais Ãºnicas: {len(regex_stats['propriedades_frequencia']) if 'regex_stats' in locals() else 0}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Dados nÃ£o disponÃ­veis para resumo final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
