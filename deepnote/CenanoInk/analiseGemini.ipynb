{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "source_hash": "8a69cc3e",
        "execution_start": 1748386979819,
        "execution_millis": 0,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "deepnote_app_block_visible": false,
        "cell_id": "af50352e6b94413fa6e6f6a0e24885a7",
        "deepnote_cell_type": "markdown"
      },
      "source": "# An√°lise de Artigos Cient√≠ficos com Gemini AI\n\n## Escopo: Nanorevestimentos e Tintas (Nanocoatings and Paints)\n\nEste notebook realiza an√°lise automatizada de artigos cient√≠ficos para identificar trabalhos relevantes ao escopo de nanorevestimentos e tintas usando a API do Google Gemini.\n\n### Funcionalidades:\n1. **Instala√ß√£o de depend√™ncias**\n2. **Configura√ß√£o da API Gemini**\n3. **Defini√ß√£o de palavras-chave espec√≠ficas**\n4. **Busca e filtro de artigos**\n5. **An√°lise individual de abstracts**\n6. **Processamento em lote com rate limiting**\n7. **Sistema de checkpoint para recupera√ß√£o**\n\n\n\n",
      "block_group": "dad07e73d3d94655ae63ca34efbf7b40"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "8b8c3a14",
        "execution_start": 1748387170533,
        "execution_millis": 4683,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "12cee1f6511a485cb4027b62ad40d337",
        "deepnote_cell_type": "code"
      },
      "source": "!pip install google.generativeai",
      "block_group": "76137c9771f24cfd859b4d28171ea726",
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: google.generativeai in /root/venv/lib/python3.11/site-packages (0.8.5)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /root/venv/lib/python3.11/site-packages (from google.generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google.generativeai) (2.19.2)\nRequirement already satisfied: google-api-python-client in /root/venv/lib/python3.11/site-packages (from google.generativeai) (2.170.0)\nRequirement already satisfied: google-auth>=2.15.0 in /root/venv/lib/python3.11/site-packages (from google.generativeai) (2.40.0)\nRequirement already satisfied: protobuf in /root/venv/lib/python3.11/site-packages (from google.generativeai) (4.25.7)\nRequirement already satisfied: pydantic in /root/venv/lib/python3.11/site-packages (from google.generativeai) (2.11.4)\nRequirement already satisfied: tqdm in /root/venv/lib/python3.11/site-packages (from google.generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /root/venv/lib/python3.11/site-packages (from google.generativeai) (4.13.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google.generativeai) (1.24.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-api-core->google.generativeai) (1.65.0)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /root/venv/lib/python3.11/site-packages (from google-api-core->google.generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google.generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google.generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google.generativeai) (4.9.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google.generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google.generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google.generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /root/venv/lib/python3.11/site-packages (from pydantic->google.generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /root/venv/lib/python3.11/site-packages (from pydantic->google.generativeai) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /root/venv/lib/python3.11/site-packages (from pydantic->google.generativeai) (0.4.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /root/venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.71.0)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.62.3)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /root/venv/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /root/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2025.4.26)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "4c28bc3d",
        "execution_start": 1748387175282,
        "execution_millis": 5181,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "27e77a47bffd4a1fbfc0da18e5bfd692",
        "deepnote_cell_type": "code"
      },
      "source": "# Instala√ß√£o das depend√™ncias necess√°rias\n!pip install google-generativeai pandas",
      "block_group": "5f0a84a5eea24314ab4e2d2ce93ac137",
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: google-generativeai in /root/venv/lib/python3.11/site-packages (0.8.5)\nRequirement already satisfied: pandas in /root/venv/lib/python3.11/site-packages (2.1.4)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /root/venv/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-generativeai) (2.19.2)\nRequirement already satisfied: google-api-python-client in /root/venv/lib/python3.11/site-packages (from google-generativeai) (2.170.0)\nRequirement already satisfied: google-auth>=2.15.0 in /root/venv/lib/python3.11/site-packages (from google-generativeai) (2.40.0)\nRequirement already satisfied: protobuf in /root/venv/lib/python3.11/site-packages (from google-generativeai) (4.25.7)\nRequirement already satisfied: pydantic in /root/venv/lib/python3.11/site-packages (from google-generativeai) (2.11.4)\nRequirement already satisfied: tqdm in /root/venv/lib/python3.11/site-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /root/venv/lib/python3.11/site-packages (from google-generativeai) (4.13.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.24.0)\nRequirement already satisfied: numpy<2,>=1.23.2 in /root/venv/lib/python3.11/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /root/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /root/venv/lib/python3.11/site-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.1 in /root/venv/lib/python3.11/site-packages (from pandas) (2025.2)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.65.0)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /root/venv/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: six>=1.5 in /root/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /root/venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /root/venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /root/venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.4.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /root/venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /root/venv/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /root/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "f3a90055",
        "execution_start": 1748387180520,
        "execution_millis": 1,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "048864eacdc74d8c8ad8c3f1dbbe69a9",
        "deepnote_cell_type": "code"
      },
      "source": "# Imports necess√°rios\nimport pandas as pd\nimport google.generativeai as genai\nimport time\nimport random\nfrom typing import List, Optional\n\n# Configura√ß√£o da API do Gemini\ngenai.configure(api_key='AIzaSyAcQicBEj8s2NvvCBORlQCgPUrPchR-vCQ')\n\nprint(\"‚úÖ Depend√™ncias carregadas e API configurada\")",
      "block_group": "3ae905ad99674f56a78b5b88eb61e67f",
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ Depend√™ncias carregadas e API configurada\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3b8a85f1f6e04c60a738891c8432bff0",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 1. Configura√ß√£o de Par√¢metros\n\nDefini√ß√£o dos par√¢metros principais para an√°lise e rate limiting da API.",
      "block_group": "b81950f9b4ca46b1a3517aa32588056a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "f56ec2a6",
        "execution_start": 1748387184152,
        "execution_millis": 3,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "6a2e3802c2d443919f091e25de67b8ce",
        "deepnote_cell_type": "code"
      },
      "source": "# Configura√ß√µes principais\nCONFIG = {\n    'modelo_gemini': 'gemini-2.0-flash-exp',  # Flash-Lite para rate limits melhores\n    'max_requests_per_minute': 30,              # Limite de requisi√ß√µes por minuto\n    'max_requests_per_day': 1400,               # Limite di√°rio recomendado\n    'delay_between_requests': 2.1,              # Delay entre requisi√ß√µes (segundos)\n    'arquivo_entrada': '/home/delon/Modelos/cenanoink/Projeto-CENanoInk/Alan Delon.csv',\n    'checkpoint_file': 'analise_escopo_checkpoint.csv',\n    'arquivo_saida': 'df_com_analise_escopo_completo.csv'\n}\n\nprint(\"üìã Configura√ß√µes carregadas:\")\nfor key, value in CONFIG.items():\n    print(f\"  {key}: {value}\")",
      "block_group": "4bb4d6da8af54405b63b83516479f60a",
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "text": "üìã Configura√ß√µes carregadas:\n  modelo_gemini: gemini-2.0-flash-exp\n  max_requests_per_minute: 30\n  max_requests_per_day: 1400\n  delay_between_requests: 2.1\n  arquivo_entrada: /home/delon/Modelos/cenanoink/Projeto-CENanoInk/Alan Delon.csv\n  checkpoint_file: analise_escopo_checkpoint.csv\n  arquivo_saida: df_com_analise_escopo_completo.csv\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "cebb84cd9b644cd9bc9d9a8a14abd116",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 2. Defini√ß√£o de Palavras-Chave\n\nConjunto abrangente de termos relacionados ao escopo de nanorevestimentos e tintas.",
      "block_group": "d54335acc51e43399f9c8cacb1622412"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "87d37ae8",
        "execution_start": 1748387191100,
        "execution_millis": 0,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "d5abb85b98574eeab0e3784dabc2652b",
        "deepnote_cell_type": "code"
      },
      "source": "# Palavras-chave organizadas por categoria\nPALAVRAS_CHAVE = {\n    'termos_principais': [\n        \"nanocoating\", \"nanocoatings\", \"nano coating\", \"nano coatings\",\n        \"nanorevestimento\", \"nanorevestimentos\", \"nanocomposite coating\"\n    ],\n    \n    'materiais_nano': [\n        \"TiO2\", \"titanium dioxide\", \"zinc oxide\", \"ZnO\", \n        \"silica nanoparticle\", \"alumina nanoparticle\", \"Al2O3\",\n        \"carbon nanotube\", \"CNT\", \"graphene\", \"iron oxide\", \"Fe2O3\",\n        \"cerium oxide\", \"CeO2\", \"clay nanoparticles\"\n    ],\n    \n    'propriedades_funcionais': [\n        \"anticorrosive coating\", \"anti-corrosion coating\",\n        \"antimicrobial coating\", \"antibacterial coating\",\n        \"self-cleaning coating\", \"superhydrophobic coating\",\n        \"photocatalytic coating\", \"UV resistant coating\",\n        \"scratch resistant coating\", \"wear resistant coating\"\n    ],\n    \n    'tecnicas_preparacao': [\n        \"sol-gel coating\", \"layer-by-layer\", \"dip coating\",\n        \"spin coating\", \"spray coating\", \"electrodeposition\",\n        \"CVD coating\", \"PVD coating\", \"plasma treatment\"\n    ],\n    \n    'aplicacoes': [\n        \"protective coating\", \"functional coating\",\n        \"smart coating\", \"intelligent coating\", \"automotive coating\",\n        \"marine coating\", \"architectural coating\", \"biomedical coating\"\n    ]\n}\n\n# Criar lista √∫nica de todas as palavras-chave\ntodas_palavras_chave = []\nfor categoria, palavras in PALAVRAS_CHAVE.items():\n    todas_palavras_chave.extend(palavras)\n\nprint(f\"üîç Total de palavras-chave definidas: {len(todas_palavras_chave)}\")\nprint(f\"üìÇ Categorias: {list(PALAVRAS_CHAVE.keys())}\")",
      "block_group": "bf0480bb9d21495c9c769e8b1e1188f4",
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "text": "üîç Total de palavras-chave definidas: 49\nüìÇ Categorias: ['termos_principais', 'materiais_nano', 'propriedades_funcionais', 'tecnicas_preparacao', 'aplicacoes']\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d5bba769a0c340f99258db2f1551ca94",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 3. Fun√ß√µes Utilit√°rias\n\nFun√ß√µes para filtro, busca e manipula√ß√£o de dados.",
      "block_group": "6d7303de5f854e09afb1006497b2a47e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "3b428172",
        "execution_start": 1748387194426,
        "execution_millis": 15,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "2b63e84812314e8b93ba707eb0190ab6",
        "deepnote_cell_type": "code"
      },
      "source": "def filtrar_coluna(df, coluna, palavra, tipo=\"contem\"):\n    \"\"\"\n    Fun√ß√£o auxiliar para filtrar uma dataframe com base em uma palavra-chave espec√≠fica.\n\n    Par√¢metros:\n    - df (DataFrame): DataFrame Pandas com os dados\n    - coluna (str): Nome da coluna a ser filtrada\n    - palavra (str): Palavra-chave usada para filtrar\n    - tipo (str): M√©todo de filtro, op√ß√µes: 'contem', 'igual'. Default √© 'contem'.\n\n    Retorno:\n    - DataFrame contendo as linhas que correspondem ao filtro\n    \"\"\"\n    if tipo == \"contem\":\n        resultado = df[df[coluna].str.contains(palavra, case=False, na=False)]\n    elif tipo == \"igual\":\n        resultado = df[df[coluna].str.lower() == palavra.lower()]\n    else:\n        raise ValueError(\"Tipo de filtro n√£o suportado. Use 'contem' ou 'igual'.\")\n\n    return resultado",
      "block_group": "3a960f469dd64c0dbefb55d61dcbd875",
      "execution_count": 28,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8a09f09331124c3c97d3c3b10b0e3aa1",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 4. An√°lise com Gemini AI\n\nFun√ß√µes para an√°lise autom√°tica de abstracts usando a API do Gemini.",
      "block_group": "1f6c6e439be54d538e5a29ef8a1f1d8b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "3a44aa35",
        "execution_start": 1748387198540,
        "execution_millis": 214283,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "f72abd9edae64664809e1e5fc54ad579",
        "deepnote_cell_type": "code"
      },
      "source": "# ...existing code...\n\ndef analisar_escopo_abstract(abstract_text):\n    \"\"\"\n    Analisa um abstract individual para determinar se se adequa ao escopo de nanorevestimentos e tintas\n    \"\"\"\n    if pd.isna(abstract_text) or str(abstract_text).strip() == '':\n        return \"N√£o se adequa - Abstract vazio ou n√£o dispon√≠vel\"\n    \n    model = genai.GenerativeModel('gemini-2.0-flash')\n    \n    prompt = f\"\"\"\n    Analise o seguinte abstract cient√≠fico e determine se ele se adequa ao escopo de pesquisa sobre \"nanorevestimentos e tintas (nanocoatings and paints)\".\n\n    Abstract: {abstract_text}\n\n    Crit√©rios para adequa√ß√£o ao escopo:\n    - Estudos sobre nanomateriais aplicados em revestimentos ou tintas\n    - Propriedades funcionais de nanocoatings (anticorros√£o, antimicrobiano, autolimpante, etc.)\n    - T√©cnicas de prepara√ß√£o ou caracteriza√ß√£o de nanorevestimentos\n    - Aplica√ß√µes industriais de tintas nanoestruturadas\n    - Materiais nanoestruturados para prote√ß√£o de superf√≠cies\n\n    Responda APENAS uma das op√ß√µes:\n    1. \"Sim - [breve justificativa]\"\n    2. \"N√£o - [breve justificativa explicando por que n√£o se adequa]\"\n\n    Mantenha a justificativa concisa (m√°ximo 100 palavras).\n    \"\"\"\n    \n    try:\n        response = model.generate_content(prompt)\n        return response.text.strip()\n    except Exception as e:\n        return f\"Erro na an√°lise - {str(e)}\"\n\ndef processar_dataframe_escopo(df, coluna_abstract='Abstract', batch_size=10):\n    \"\"\"\n    Processa todo o DataFrame adicionando a coluna de adequa√ß√£o ao escopo\n    \"\"\"\n    # Verificar se a coluna Abstract existe\n    if coluna_abstract not in df.columns:\n        print(f\"Coluna '{coluna_abstract}' n√£o encontrada no DataFrame\")\n        return df\n    \n    # Criar uma c√≥pia do DataFrame\n    df_processado = df.copy()\n    \n    # Inicializar a nova coluna\n    df_processado['Se adequa ao escopo?'] = ''\n    \n    total_linhas = len(df_processado)\n    print(f\"Processando {total_linhas} abstracts...\")\n    \n    # Processar em lotes para evitar sobrecarga da API\n    for i in range(0, total_linhas, batch_size):\n        batch_end = min(i + batch_size, total_linhas)\n        print(f\"Processando linhas {i+1} a {batch_end}...\")\n        \n        for idx in range(i, batch_end):\n            abstract = df_processado.iloc[idx][coluna_abstract]\n            resultado = analisar_escopo_abstract(abstract)\n            df_processado.iloc[idx, df_processado.columns.get_loc('Se adequa ao escopo?')] = resultado\n            \n            # Mostrar progresso\n            if (idx + 1) % 5 == 0:\n                print(f\"  Processado: {idx + 1}/{total_linhas}\")\n        \n        # Pequena pausa entre lotes para n√£o sobrecarregar a API\n        import time\n        time.sleep(2)\n    \n    return df_processado\n\n# Carregar o DataFrame\ndf = pd.read_csv('/work/ExtensaoemCienciadeDadosUece/Imers√£o - CenanoInk/Alan Delon.csv')\n\nprint(\"Informa√ß√µes do DataFrame:\")\nprint(f\"Total de linhas: {len(df)}\")\nprint(f\"Colunas dispon√≠veis: {list(df.columns)}\")\n\n# Verificar se existe coluna Abstract\nif 'Abstract' in df.columns:\n    print(f\"Abstracts n√£o vazios: {df['Abstract'].notna().sum()}\")\n    \n    # Processar apenas uma amostra primeiro (para teste)\n    print(\"\\n=== PROCESSAMENTO DE TESTE (primeiras 5 linhas) ===\")\n    df_teste = df.head(5).copy()\n    df_teste_processado = processar_dataframe_escopo(df_teste, batch_size=1)\n    \n    print(\"\\nResultados do teste:\")\n    for idx, row in df_teste_processado.iterrows():\n        print(f\"\\nLinha {idx + 1}:\")\n        print(f\"T√≠tulo: {row.get('Article Title', 'N/A')[:100]}...\")\n        print(f\"Adequa√ß√£o: {row['Se adequa ao escopo?']}\")\n    \n    # Perguntar se deseja processar todo o DataFrame\n    resposta = input(\"\\nDeseja processar todo o DataFrame? (s/n): \")\n    if resposta.lower() == 's':\n        print(\"\\n=== PROCESSANDO TODO O DATAFRAME ===\")\n        df_completo = processar_dataframe_escopo(df)\n        \n        # Salvar resultado\n        arquivo_saida = 'df_com_analise_escopo.csv'\n        df_completo.to_csv(arquivo_saida, index=False)\n        print(f\"\\nResultados salvos em: {arquivo_saida}\")\n        \n        # Mostrar estat√≠sticas\n        adequados = df_completo['Se adequa ao escopo?'].str.contains('Sim', case=False, na=False).sum()\n        nao_adequados = df_completo['Se adequa ao escopo?'].str.contains('N√£o', case=False, na=False).sum()\n        \n        print(f\"\\n=== ESTAT√çSTICAS FINAIS ===\")\n        print(f\"Adequados ao escopo: {adequados}\")\n        print(f\"N√£o adequados ao escopo: {nao_adequados}\")\n        print(f\"Total processado: {adequados + nao_adequados}\")\n        \nelse:\n    print(\"Coluna 'Abstract' n√£o encontrada no DataFrame\")\n    print(\"Colunas dispon√≠veis:\", list(df.columns))",
      "block_group": "ab3dcba9461f46b980b51b4101a4dfab",
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "text": "Informa√ß√µes do DataFrame:\nTotal de linhas: 525\nColunas dispon√≠veis: ['Publication Type', 'Authors', 'Book Authors', 'Book Editors', 'Book Group Authors', 'Author Full Names', 'Book Author Full Names', 'Group Authors', 'Article Title', 'Source Title', 'Book Series Title', 'Book Series Subtitle', 'Language', 'Document Type', 'Conference Title', 'Conference Date', 'Conference Location', 'Conference Sponsor', 'Conference Host', 'Author Keywords', 'Keywords Plus', 'Abstract', 'Addresses', 'Affiliations', 'Reprint Addresses', 'Email Addresses', 'Researcher Ids', 'ORCIDs', 'Funding Orgs', 'Funding Name Preferred', 'Funding Text', 'Cited References', 'Cited Reference Count', 'Times Cited, WoS Core', 'Times Cited, All Databases', '180 Day Usage Count', 'Since 2013 Usage Count', 'Publisher', 'Publisher City', 'Publisher Address', 'ISSN', 'eISSN', 'ISBN', 'Journal Abbreviation', 'Journal ISO Abbreviation', 'Publication Date', 'Publication Year', 'Volume', 'Issue', 'Part Number', 'Supplement', 'Special Issue', 'Meeting Abstract', 'Start Page', 'End Page', 'Article Number', 'DOI', 'DOI Link', 'Book DOI', 'Early Access Date', 'Number of Pages', 'WoS Categories', 'Web of Science Index', 'Research Areas', 'IDS Number', 'Pubmed Id', 'Open Access Designations', 'Highly Cited Status', 'Hot Paper Status', 'Date of Export', 'UT (Unique WOS ID)', 'Web of Science Record', 'Unnamed: 72']\nAbstracts n√£o vazios: 525\n\n=== PROCESSAMENTO DE TESTE (primeiras 5 linhas) ===\nProcessando 5 abstracts...\nProcessando linhas 1 a 1...\nProcessando linhas 2 a 2...\nProcessando linhas 3 a 3...\nProcessando linhas 4 a 4...\nProcessando linhas 5 a 5...\n  Processado: 5/5\n\nResultados do teste:\n\nLinha 1:\nT√≠tulo: Ab Initio Study of the Atomic Level Structure of the Rutile TiO2(110) -Titanium Nitride (TiN) Interf...\nAdequa√ß√£o: 1.  \"Sim - O abstract descreve um estudo te√≥rico (DFT) da interface entre TiN (nitreto de tit√¢nio) e TiO2 (√≥xido de tit√¢nio), que se forma como uma fina camada de √≥xido na superf√≠cie do TiN. TiN √© usado como revestimento protetor devido √† sua dureza e resist√™ncia √† corros√£o. O estudo das propriedades estruturais e eletr√¥nicas dessa interface, especialmente a influ√™ncia de defeitos e n√£o-estequiometria, √© relevante para entender e otimizar o desempenho do nanorrevestimento de TiN.\"\n\nLinha 2:\nT√≠tulo: Polymer and ceramic nanocomposites for aerospace applications...\nAdequa√ß√£o: Sim - Embora o abstract foque em comp√≥sitos polim√©ricos e cer√¢micos com aplica√ß√µes aeroespaciais, ele menciona revestimentos (coating) como uma aplica√ß√£o dentro de comp√≥sitos de matriz polim√©rica. A discuss√£o sobre propriedades multifuncionais devido √† dispers√£o de nanopart√≠culas tamb√©m est√° alinhada com o escopo de nanorevestimentos.\n\nLinha 3:\nT√≠tulo: Recycling of yttria-stabilized zirconia waste powders in glazes suitable for ceramic tiles...\nAdequa√ß√£o: 2. \"N√£o - O abstract descreve a reciclagem de res√≠duos de zirc√¥nia estabilizada com √≠trio para a produ√ß√£o de fritas para esmaltes e revestimentos cer√¢micos, focando na substitui√ß√£o da zirc√¥nia pura. Embora envolva materiais cer√¢micos, n√£o menciona o uso de *nano*materiais ou *nano*revestimentos/tintas, nem aborda as propriedades funcionais ou t√©cnicas de prepara√ß√£o/caracteriza√ß√£o de *nano*revestimentos. O foco √© na aplica√ß√£o em esmaltes cer√¢micos, n√£o em nanorrevestimentos ou tintas nanoestruturadas.\"\n\nLinha 4:\nT√≠tulo: Properties of Polysiloxane Coated Borosilicate Lining Blocks...\nAdequa√ß√£o: 1.  \"Sim - O abstract descreve a aplica√ß√£o de uma slurry contendo fumed silica (s√≠lica fumada, que pode estar na nanoescala) como revestimento em um bloco de borosilicato para melhorar a resist√™ncia t√©rmica. A caracteriza√ß√£o do material e a an√°lise das propriedades t√©rmicas do revestimento se encaixam no escopo.\"\n\nLinha 5:\nT√≠tulo: Solution Processed Porous Fe2O3 Thin Films for Solar-Driven Water Splitting...\nAdequa√ß√£o: N√£o - O abstract descreve a prepara√ß√£o e caracteriza√ß√£o de filmes finos de hematita (Œ±-Fe2O3) para aplica√ß√£o em divis√£o de √°gua fotoeletroqu√≠mica, n√£o em revestimentos ou tintas. O foco est√° na performance fotoeletroqu√≠mica e n√£o nas propriedades t√≠picas de nanocoatings como anticorros√£o, antimicrobiano, etc., ou em aplica√ß√µes industriais de tintas.\n\n=== PROCESSANDO TODO O DATAFRAME ===\nProcessando 525 abstracts...\nProcessando linhas 1 a 10...\n  Processado: 5/525\n  Processado: 10/525\nProcessando linhas 11 a 20...\n  Processado: 15/525\n  Processado: 20/525\nProcessando linhas 21 a 30...\n  Processado: 25/525\n  Processado: 30/525\nProcessando linhas 31 a 40...\n  Processado: 35/525\n  Processado: 40/525\nProcessando linhas 41 a 50...\n  Processado: 45/525\n  Processado: 50/525\nProcessando linhas 51 a 60...\n  Processado: 55/525\n  Processado: 60/525\nProcessando linhas 61 a 70...\n  Processado: 65/525\n  Processado: 70/525\nProcessando linhas 71 a 80...\n  Processado: 75/525\n  Processado: 80/525\nProcessando linhas 81 a 90...\n  Processado: 85/525\n  Processado: 90/525\nProcessando linhas 91 a 100...\n  Processado: 95/525\n  Processado: 100/525\nProcessando linhas 101 a 110...\n  Processado: 105/525\n  Processado: 110/525\nProcessando linhas 111 a 120...\n  Processado: 115/525\n  Processado: 120/525\nProcessando linhas 121 a 130...\n  Processado: 125/525\n  Processado: 130/525\nProcessando linhas 131 a 140...\n  Processado: 135/525\n  Processado: 140/525\nProcessando linhas 141 a 150...\n  Processado: 145/525\n  Processado: 150/525\nProcessando linhas 151 a 160...\n  Processado: 155/525\n  Processado: 160/525\nProcessando linhas 161 a 170...\n  Processado: 165/525\n  Processado: 170/525\nProcessando linhas 171 a 180...\n  Processado: 175/525\n  Processado: 180/525\nProcessando linhas 181 a 190...\n  Processado: 185/525\n  Processado: 190/525\nProcessando linhas 191 a 200...\n  Processado: 195/525\n  Processado: 200/525\nProcessando linhas 201 a 210...\n  Processado: 205/525\n  Processado: 210/525\nProcessando linhas 211 a 220...\n  Processado: 215/525\n  Processado: 220/525\nProcessando linhas 221 a 230...\n  Processado: 225/525\n  Processado: 230/525\nProcessando linhas 231 a 240...\n  Processado: 235/525\n  Processado: 240/525\nProcessando linhas 241 a 250...\n  Processado: 245/525\n  Processado: 250/525\nProcessando linhas 251 a 260...\n  Processado: 255/525\n  Processado: 260/525\nProcessando linhas 261 a 270...\n  Processado: 265/525\n  Processado: 270/525\nProcessando linhas 271 a 280...\n  Processado: 275/525\n  Processado: 280/525\nProcessando linhas 281 a 290...\n  Processado: 285/525\n  Processado: 290/525\nProcessando linhas 291 a 300...\n  Processado: 295/525\n  Processado: 300/525\nProcessando linhas 301 a 310...\n  Processado: 305/525\n  Processado: 310/525\nProcessando linhas 311 a 320...\n  Processado: 315/525\n  Processado: 320/525\nProcessando linhas 321 a 330...\n  Processado: 325/525\n  Processado: 330/525\nProcessando linhas 331 a 340...\n  Processado: 335/525\n  Processado: 340/525\nProcessando linhas 341 a 350...\n  Processado: 345/525\n  Processado: 350/525\nProcessando linhas 351 a 360...\n  Processado: 355/525\n  Processado: 360/525\nProcessando linhas 361 a 370...\n  Processado: 365/525\n  Processado: 370/525\nProcessando linhas 371 a 380...\n  Processado: 375/525\n  Processado: 380/525\nProcessando linhas 381 a 390...\n  Processado: 385/525\n  Processado: 390/525\nProcessando linhas 391 a 400...\n  Processado: 395/525\n  Processado: 400/525\nProcessando linhas 401 a 410...\n  Processado: 405/525\n  Processado: 410/525\nProcessando linhas 411 a 420...\n  Processado: 415/525\n  Processado: 420/525\nProcessando linhas 421 a 430...\n  Processado: 425/525\n  Processado: 430/525\nProcessando linhas 431 a 440...\n  Processado: 435/525\n  Processado: 440/525\nProcessando linhas 441 a 450...\n  Processado: 445/525\n  Processado: 450/525\nProcessando linhas 451 a 460...\n  Processado: 455/525\n  Processado: 460/525\nProcessando linhas 461 a 470...\n  Processado: 465/525\n  Processado: 470/525\nProcessando linhas 471 a 480...\n  Processado: 475/525\n  Processado: 480/525\nProcessando linhas 481 a 490...\n  Processado: 485/525\n  Processado: 490/525\nProcessando linhas 491 a 500...\n  Processado: 495/525\n  Processado: 500/525\nProcessando linhas 501 a 510...\n  Processado: 505/525\n  Processado: 510/525\nProcessando linhas 511 a 520...\n  Processado: 515/525\n  Processado: 520/525\nProcessando linhas 521 a 525...\n  Processado: 525/525\n\nResultados salvos em: df_com_analise_escopo.csv\n\n=== ESTAT√çSTICAS FINAIS ===\nAdequados ao escopo: 26\nN√£o adequados ao escopo: 47\nTotal processado: 73\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9eee10dcfba1467d8b83fef58d192181",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 5. Processamento em Lote\n\nFun√ß√µes para processar grandes volumes de dados respeitando rate limits.",
      "block_group": "3a4a7229dc854d46af36dd96c7738edd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "46887e56",
        "execution_start": 1748387503634,
        "execution_millis": 0,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "6e8d81de55474eb5b5c808a167db3ad4",
        "deepnote_cell_type": "code"
      },
      "source": "import pandas as pd\nimport random\nimport time\nfrom typing import List\n\n# Fixing imports and cleaning up erroneous duplicated or corrupted lines in the code.\ndef analisar_escopo_abstract(abstract_text: str, retry_count: int = 3) -> str:\n    \"\"\"\n    Analisa um abstract individual para determinar se se adequa ao escopo de nanorevestimentos e tintas usando Gemini 2.0 Flash-Lite.\n\n    Args:\n        abstract_text: Texto do abstract.\n        retry_count: N√∫mero de tentativas em caso de erro.\n\n    Returns:\n        String com resultado da an√°lise.\n    \"\"\"\n    if pd.isna(abstract_text) or str(abstract_text).strip() == '':\n        return \"N√£o se adequa - Abstract vazio ou n√£o dispon√≠vel\"\n\n    # Placeholder for initializing the model\n    try:\n        model = genai.GenerativeModel(CONFIG['modelo_gemini'])\n    except NameError:\n        raise Exception(\"CONFIG or genai module not properly configured\")\n\n    prompt = f\"\"\"\n    Analise o seguinte abstract cient√≠fico e determine se ele se adequa ao escopo de pesquisa sobre \"nanorevestimentos e tintas (nanocoatings and paints)\".\n\n    Abstract: {abstract_text}\n\n    Crit√©rios para adequa√ß√£o ao escopo:\n        - Materiais nanoestruturados para prote√ß√£o de superf√≠cies\n        - Estudos sobre nanomateriais aplicados em revestimentos ou tintas\n        - Propriedades funcionais de nanocoatings (anticorros√£o, antimicrobiano, autolimpante, etc.)\n        - T√©cnicas de prepara√ß√£o ou caracteriza√ß√£o de nanorevestimentos\n        - Aplica√ß√µes industriais de tintas nanoestruturadas\n\n    Responda APENAS uma das op√ß√µes:\n        1. \"Sim - [breve justificativa]\"\n        2. \"N√£o - [breve justificativa explicando por que n√£o se adequa]\"\n\n    Mantenha a justificativa concisa (m√°ximo 100 palavras).\n    \"\"\"\n\n    for attempt in range(retry_count):\n        try:\n            response = model.generate_content(prompt)\n            return response.text.strip()\n        except Exception as e:\n            error_msg = str(e)\n            if \"429\" in error_msg or \"quota\" in error_msg.lower():\n                if attempt < retry_count - 1:\n                    wait_time = 3 + random.randint(1, 2)\n                    print(f\"  ‚è≥ Rate limit - aguardando {wait_time}s...\")\n                    time.sleep(wait_time)\n                    continue\n                else:\n                    return f\"Erro - Rate limit excedido ap√≥s {retry_count} tentativas\"\n            return f\"Erro na an√°lise - {error_msg}\"\n\n    return \"Erro - Falha ap√≥s m√∫ltiplas tentativas\"",
      "block_group": "0abc433754b44dba8763ce3e02066b69",
      "execution_count": 34,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "99bbfdbfe8e7432e9241a937d2ecc8d1",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 6. Execu√ß√£o Principal\n\nScript principal para carregar dados e executar an√°lises.",
      "block_group": "80483a10bb7f4b5abde919f31eaaa694"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "54f788e0",
        "execution_start": 1748387521738,
        "execution_millis": 416,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "3fd24c99c5944d339e143f1b21acf3aa",
        "deepnote_cell_type": "code"
      },
      "source": "# Carregar e explorar os dados\nprint(\"üìÇ Carregando dados...\")\n\ntry:\n    df = pd.read_csv(\"/work/ExtensaoemCienciadeDadosUece/Imers√£o - CenanoInk/Alan Delon.csv\")\n    print(f\"‚úÖ Dados carregados com sucesso\")\n    print(f\"üìä Total de linhas: {len(df):,}\")\n    print(f\"üìä Total de colunas: {len(df.columns)}\")\n    print(f\"üìã Colunas dispon√≠veis: {list(df.columns)}\")\n    \n    # Verificar colunas essenciais\n    colunas_essenciais = ['Article Title', 'Abstract']\n    colunas_encontradas = [col for col in colunas_essenciais if col in df.columns]\n    colunas_faltantes = [col for col in colunas_essenciais if col not in df.columns]\n    \n    print(f\"\\n‚úÖ Colunas encontradas: {colunas_encontradas}\")\n    if colunas_faltantes:\n        print(f\"‚ö†Ô∏è Colunas faltantes: {colunas_faltantes}\")\n    \n    # Estat√≠sticas dos abstracts\n    if 'Abstract' in df.columns:\n        abstracts_validos = df['Abstract'].notna().sum()\n        abstracts_vazios = df['Abstract'].isna().sum()\n        print(f\"\\nüìÑ Abstracts dispon√≠veis: {abstracts_validos:,}\")\n        print(f\"üìÑ Abstracts vazios: {abstracts_vazios:,}\")\n        print(f\"üìÑ Taxa de completude: {(abstracts_validos/len(df))*100:.1f}%\")\n    \nexcept FileNotFoundError:\n    print(f\"‚ùå Arquivo n√£o encontrado: {CONFIG['arquivo_entrada']}\")\n    df = None\nexcept Exception as e:\n    print(f\"‚ùå Erro ao carregar dados: {e}\")\n    df = None",
      "block_group": "c9d85e9fcf374491a8a22b116c00ba31",
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "text": "üìÇ Carregando dados...\n‚úÖ Dados carregados com sucesso\nüìä Total de linhas: 525\nüìä Total de colunas: 73\nüìã Colunas dispon√≠veis: ['Publication Type', 'Authors', 'Book Authors', 'Book Editors', 'Book Group Authors', 'Author Full Names', 'Book Author Full Names', 'Group Authors', 'Article Title', 'Source Title', 'Book Series Title', 'Book Series Subtitle', 'Language', 'Document Type', 'Conference Title', 'Conference Date', 'Conference Location', 'Conference Sponsor', 'Conference Host', 'Author Keywords', 'Keywords Plus', 'Abstract', 'Addresses', 'Affiliations', 'Reprint Addresses', 'Email Addresses', 'Researcher Ids', 'ORCIDs', 'Funding Orgs', 'Funding Name Preferred', 'Funding Text', 'Cited References', 'Cited Reference Count', 'Times Cited, WoS Core', 'Times Cited, All Databases', '180 Day Usage Count', 'Since 2013 Usage Count', 'Publisher', 'Publisher City', 'Publisher Address', 'ISSN', 'eISSN', 'ISBN', 'Journal Abbreviation', 'Journal ISO Abbreviation', 'Publication Date', 'Publication Year', 'Volume', 'Issue', 'Part Number', 'Supplement', 'Special Issue', 'Meeting Abstract', 'Start Page', 'End Page', 'Article Number', 'DOI', 'DOI Link', 'Book DOI', 'Early Access Date', 'Number of Pages', 'WoS Categories', 'Web of Science Index', 'Research Areas', 'IDS Number', 'Pubmed Id', 'Open Access Designations', 'Highly Cited Status', 'Hot Paper Status', 'Date of Export', 'UT (Unique WOS ID)', 'Web of Science Record', 'Unnamed: 72']\n\n‚úÖ Colunas encontradas: ['Article Title', 'Abstract']\n\nüìÑ Abstracts dispon√≠veis: 525\nüìÑ Abstracts vazios: 0\nüìÑ Taxa de completude: 100.0%\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "88037aed",
        "execution_start": 1748387574780,
        "execution_millis": 0,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "e258f6ef43e04dfa994d4ea4f2329c12",
        "deepnote_cell_type": "code"
      },
      "source": "def buscar_artigos_por_palavras_chave(df, palavras_chave):\n    \"\"\"\n    Filtra os artigos em um DataFrame com base em uma lista de palavras-chave.\n\n    Args:\n        df (pd.DataFrame): DataFrame contendo os artigos.\n        palavras_chave (List[str]): Lista de palavras-chave para buscar nos abstracts ou t√≠tulos.\n\n    Returns:\n        pd.DataFrame: DataFrame com os artigos que cont√™m as palavras-chave.\n    \"\"\"\n    if 'Abstract' not in df.columns or 'Article Title' not in df.columns:\n        raise ValueError(\"O DataFrame deve conter as colunas 'Abstract' e 'Article Title'\")\n\n    # Criar um filtro para verificar se as palavras-chave aparecem no t√≠tulo ou resumo\n    filtro = (df['Abstract'].str.contains('|'.join(palavras_chave), case=False, na=False) |\n              df['Article Title'].str.contains('|'.join(palavras_chave), case=False, na=False))\n\n    # Aplicar o filtro ao DataFrame\n    return df[filtro].copy()",
      "block_group": "067684ac8e464eee9758df17b12bcbcd",
      "execution_count": 43,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "d7544e9e",
        "execution_start": 1748387597156,
        "execution_millis": 5,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "623e8051c39544feac26910eb7d09406",
        "deepnote_cell_type": "code"
      },
      "source": "def processar_com_checkpoint(df, checkpoint_file='checkpoint.csv', batch_size=10):\n    \"\"\"\n    Processa o DataFrame em lotes e salva checkpoints em um arquivo CSV intermedi√°rio para recupera√ß√£o.\n\n    Args:\n        df (pd.DataFrame): DataFrame a ser processado.\n        checkpoint_file (str): Nome do arquivo de checkpoint.\n        batch_size (int): N√∫mero de linhas a serem processadas por lote.\n\n    Returns:\n        pd.DataFrame: DataFrame com os resultados do processamento.\n    \"\"\"\n    import os\n    import pandas as pd\n\n    # Carregar checkpoint se j√° existir\n    if os.path.exists(checkpoint_file):\n        df_checkpoint = pd.read_csv(checkpoint_file)\n        processed_ids = set(df_checkpoint['ID'])\n        print(f\"üîÑ Checkpoint encontrado. {len(processed_ids):,} linhas j√° processadas.\")\n    else:\n        df_checkpoint = pd.DataFrame()\n        processed_ids = set()\n\n    # Identificar IDs a processar\n    df['ID'] = df.index  # Garantir uma coluna ID √∫nica\n    to_process = df[~df['ID'].isin(processed_ids)]\n\n    print(f\"üöÄ Iniciando processamento com checkpoint...\")\n    total = len(to_process)\n\n    for start in range(0, total, batch_size):\n        end = min(start + batch_size, total)\n        batch = to_process.iloc[start:end]\n        print(f\"üî¨ Processando linhas {start + 1} a {end}/{total}...\")\n\n        # Executar an√°lise lotes\n        batch['Se adequa ao escopo?'] = batch['Abstract'].apply(analisar_escopo_abstract)\n\n        # Adicionar ao checkpoint\n        df_checkpoint = pd.concat([df_checkpoint, batch], ignore_index=True)\n\n        # Salvar checkpoint\n        df_checkpoint.to_csv(checkpoint_file, index=False)\n\n        print(f\"‚úîÔ∏è Checkpoint salvo: {checkpoint_file}\")\n\n    print(\"‚úÖ Processamento conclu√≠do.\")\n    return df_checkpoint",
      "block_group": "554fe6e7cd474ea5b608553debd06248",
      "execution_count": 52,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd6f7c35177049a0a2f878501e039b53",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 7. Conclus√£o\n\n### Funcionalidades implementadas:\n\n1. ‚úÖ **Busca por palavras-chave**: Sistema robusto de filtro com m√∫ltiplas categorias\n2. ‚úÖ **An√°lise com Gemini AI**: An√°lise autom√°tica de relev√¢ncia dos abstracts\n3. ‚úÖ **Rate limiting**: Respeita limites da API (30 req/min, 1.500 req/dia)\n4. ‚úÖ **Sistema de checkpoint**: Permite retomar an√°lises interrompidas\n5. ‚úÖ **Estat√≠sticas detalhadas**: M√©tricas de adequa√ß√£o e performance\n6. ‚úÖ **Exporta√ß√£o de dados**: Salva resultados em formato CSV\n\n### Arquivos gerados:\n- `artigos_nanorevestimentos_encontrados.csv`: Artigos filtrados por palavras-chave\n- `analise_escopo_checkpoint.csv`: Checkpoint do processamento\n- `df_com_analise_escopo_completo.csv`: An√°lise completa com Gemini\n\n### Pr√≥ximos passos:\n- Refinar palavras-chave com base nos resultados\n- Implementar an√°lise de trends temporais\n- Adicionar an√°lise de colabora√ß√µes e redes\n- Desenvolver dashboard interativo",
      "block_group": "b72e5ebeb21345c19e82e19c1d0c9a2b"
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d35fdc8b-8543-45dc-ae25-3ba609dd01b9' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "848a9951670d45caa2f76f00e5ba2236"
  }
}