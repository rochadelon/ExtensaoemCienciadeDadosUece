{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "source_hash": "8a69cc3e",
        "execution_start": 1748386979819,
        "execution_millis": 0,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "deepnote_app_block_visible": false,
        "cell_id": "af50352e6b94413fa6e6f6a0e24885a7",
        "deepnote_cell_type": "markdown"
      },
      "source": "# Análise de Artigos Científicos com Gemini AI\n\n## Escopo: Nanorevestimentos e Tintas (Nanocoatings and Paints)\n\nEste notebook realiza análise automatizada de artigos científicos para identificar trabalhos relevantes ao escopo de nanorevestimentos e tintas usando a API do Google Gemini.\n\n### Funcionalidades:\n1. **Instalação de dependências**\n2. **Configuração da API Gemini**\n3. **Definição de palavras-chave específicas**\n4. **Busca e filtro de artigos**\n5. **Análise individual de abstracts**\n6. **Processamento em lote com rate limiting**\n7. **Sistema de checkpoint para recuperação**\n\n\n\n",
      "block_group": "dad07e73d3d94655ae63ca34efbf7b40"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "8b8c3a14",
        "execution_start": 1748387170533,
        "execution_millis": 4683,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "12cee1f6511a485cb4027b62ad40d337",
        "deepnote_cell_type": "code"
      },
      "source": "!pip install google.generativeai",
      "block_group": "76137c9771f24cfd859b4d28171ea726",
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: google.generativeai in /root/venv/lib/python3.11/site-packages (0.8.5)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /root/venv/lib/python3.11/site-packages (from google.generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google.generativeai) (2.19.2)\nRequirement already satisfied: google-api-python-client in /root/venv/lib/python3.11/site-packages (from google.generativeai) (2.170.0)\nRequirement already satisfied: google-auth>=2.15.0 in /root/venv/lib/python3.11/site-packages (from google.generativeai) (2.40.0)\nRequirement already satisfied: protobuf in /root/venv/lib/python3.11/site-packages (from google.generativeai) (4.25.7)\nRequirement already satisfied: pydantic in /root/venv/lib/python3.11/site-packages (from google.generativeai) (2.11.4)\nRequirement already satisfied: tqdm in /root/venv/lib/python3.11/site-packages (from google.generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /root/venv/lib/python3.11/site-packages (from google.generativeai) (4.13.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google.generativeai) (1.24.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-api-core->google.generativeai) (1.65.0)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /root/venv/lib/python3.11/site-packages (from google-api-core->google.generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google.generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google.generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google.generativeai) (4.9.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google.generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google.generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google.generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /root/venv/lib/python3.11/site-packages (from pydantic->google.generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /root/venv/lib/python3.11/site-packages (from pydantic->google.generativeai) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /root/venv/lib/python3.11/site-packages (from pydantic->google.generativeai) (0.4.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /root/venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.71.0)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.62.3)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /root/venv/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /root/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2025.4.26)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "4c28bc3d",
        "execution_start": 1748389559970,
        "execution_millis": 5077,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "27e77a47bffd4a1fbfc0da18e5bfd692",
        "deepnote_cell_type": "code"
      },
      "source": "# Instalação das dependências necessárias\n!pip install google-generativeai pandas",
      "block_group": "5f0a84a5eea24314ab4e2d2ce93ac137",
      "execution_count": 91,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: google-generativeai in /root/venv/lib/python3.11/site-packages (0.8.5)\nRequirement already satisfied: pandas in /root/venv/lib/python3.11/site-packages (2.1.4)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /root/venv/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-generativeai) (2.19.2)\nRequirement already satisfied: google-api-python-client in /root/venv/lib/python3.11/site-packages (from google-generativeai) (2.170.0)\nRequirement already satisfied: google-auth>=2.15.0 in /root/venv/lib/python3.11/site-packages (from google-generativeai) (2.40.0)\nRequirement already satisfied: protobuf in /root/venv/lib/python3.11/site-packages (from google-generativeai) (4.25.7)\nRequirement already satisfied: pydantic in /root/venv/lib/python3.11/site-packages (from google-generativeai) (2.11.4)\nRequirement already satisfied: tqdm in /root/venv/lib/python3.11/site-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /root/venv/lib/python3.11/site-packages (from google-generativeai) (4.13.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.24.0)\nRequirement already satisfied: numpy<2,>=1.23.2 in /root/venv/lib/python3.11/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /root/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /root/venv/lib/python3.11/site-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.1 in /root/venv/lib/python3.11/site-packages (from pandas) (2025.2)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.65.0)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /root/venv/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /root/venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: six>=1.5 in /root/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /root/venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /root/venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /root/venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /root/venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.4.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /root/venv/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /root/venv/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /root/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /root/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "efc8e536",
        "execution_start": 1748389569643,
        "execution_millis": 8,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "048864eacdc74d8c8ad8c3f1dbbe69a9",
        "deepnote_cell_type": "code"
      },
      "source": "# Imports necessários\nimport pandas as pd\nimport google.generativeai as genai\nimport time\nimport random\nfrom typing import List, Optional\n\n# Configuração da API do Gemini\ngenai.configure(api_key='AIzaSyA_wEQ0XgcJNy9Yw58sH94VBeI14mpH9b0')\n\nprint(\"✅ Dependências carregadas e API configurada\")",
      "block_group": "3ae905ad99674f56a78b5b88eb61e67f",
      "execution_count": 94,
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ Dependências carregadas e API configurada\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3b8a85f1f6e04c60a738891c8432bff0",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 1. Configuração de Parâmetros\n\nDefinição dos parâmetros principais para análise e rate limiting da API.",
      "block_group": "b81950f9b4ca46b1a3517aa32588056a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "fc8c0112",
        "execution_start": 1748389698130,
        "execution_millis": 0,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "6a2e3802c2d443919f091e25de67b8ce",
        "deepnote_cell_type": "code"
      },
      "source": "# Configurações principais\nCONFIG = {\n    'modelo_gemini': 'Gemini 2.0 Flash-Lite',  # Flash-Lite para rate limits melhores\n    'max_requests_per_minute': 10,              # Limite de requisições por minuto\n    'max_requests_per_day': 1400,               # Limite diário recomendado\n    'delay_between_requests': 2.1,              # Delay entre requisições (segundos)\n    'arquivo_entrada': '/home/delon/Modelos/cenanoink/Projeto-CENanoInk/Alan Delon.csv',\n    'checkpoint_file': 'analise_escopo_checkpoint.csv',\n    'arquivo_saida': 'df_com_analise_escopo_completo.csv'\n}\n\nprint(\"📋 Configurações carregadas:\")\nfor key, value in CONFIG.items():\n    print(f\"  {key}: {value}\")",
      "block_group": "4bb4d6da8af54405b63b83516479f60a",
      "execution_count": 103,
      "outputs": [
        {
          "name": "stdout",
          "text": "📋 Configurações carregadas:\n  modelo_gemini: Gemini 2.0 Flash-Lite\n  max_requests_per_minute: 10\n  max_requests_per_day: 1400\n  delay_between_requests: 2.1\n  arquivo_entrada: /home/delon/Modelos/cenanoink/Projeto-CENanoInk/Alan Delon.csv\n  checkpoint_file: analise_escopo_checkpoint.csv\n  arquivo_saida: df_com_analise_escopo_completo.csv\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "cebb84cd9b644cd9bc9d9a8a14abd116",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 2. Definição de Palavras-Chave\n\nConjunto abrangente de termos relacionados ao escopo de nanorevestimentos e tintas.",
      "block_group": "d54335acc51e43399f9c8cacb1622412"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "101dc115",
        "execution_start": 1748389702146,
        "execution_millis": 1,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "d5abb85b98574eeab0e3784dabc2652b",
        "deepnote_cell_type": "code"
      },
      "source": "# Palavras-chave organizadas por categoria\n\n\n\nPALAVRAS_CHAVE = {\n    'main_terms': [\n        \"nanocoating\", \"nanocoatings\", \"nano coating\", \"nano coatings\",\n        \"nanocomposite coating\",\n        \"nanoparticle coating\", \"nanostructured coating\", \"thin film coating\",\n        \"nanopaint\", \"nanopaints\", \"nano paint\", \"nano paints\",\n        \"nanotechnological paint\", \"nanotechnological paints\",\n        \"nanotechnological coating\", \"nanotechnological coatings\",\n        \"nanocomposite paint\", \"nanoparticle enhanced paint\"\n    ],\n    \n    'nano_materials': [\n        \"TiO2\", \"titanium dioxide\",\n        \"zinc oxide\", \"ZnO\",\n        \"silica nanoparticle\", \"SiO2\",\n        \"alumina nanoparticle\", \"Al2O3\",\n        \"carbon nanotube\", \"CNT\",\n        \"graphene\", \"graphene oxide\",\n        \"iron oxide\", \"Fe2O3\", \"Fe3O4\",\n        \"cerium oxide\", \"CeO2\",\n        \"silver nanoparticles\", \"AgNPs\",\n        \"gold nanoparticles\", \"AuNPs\",\n        \"quantum dots\",\n        \"nanoclays\", \"clay nanoparticles\", \"montmorillonite\",\n        \"polymeric nanoparticles\",\n        \"nanocellulose\", \"cellulose nanocrystals\"\n    ],\n    \n    'functional_properties': [\n        \"anticorrosive coating\", \"anti-corrosion coating\",\n        \"antimicrobial coating\", \"antibacterial coating\", \"antifungal coating\", \"antiviral coating\",\n        \"self-healing coating\", \"self-repairing coating\",\n        \"self-cleaning coating\", \"superhydrophobic coating\", \"hydrophobic coating\", \"oleophobic coating\",\n        \"photocatalytic coating\",\n        \"UV resistant coating\", \"UV protection\", \"UV blocker\",\n        \"scratch resistant coating\", \"anti-scratch\",\n        \"wear resistant coating\", \"abrasion resistant coating\",\n        \"thermal barrier coating\", \"thermal insulation\",\n        \"flame retardant coating\", \"fire retardant\",\n        \"anti-fouling coating\",\n        \"conductive coating\",\n        \"anti-static coating\",\n        \"barrier coating (gas, moisture)\",\n        \"easy-to-clean\",\n        \"enhanced adhesion\",\n        \"corrosion inhibitor\",\n        \"biocidal properties\"\n    ],\n    \n    'preparation_techniques': [\n        \"sol-gel coating\", \"sol-gel process\",\n        \"layer-by-layer assembly\", \"LbL\",\n        \"dip coating\",\n        \"spin coating\",\n        \"spray coating\", \"air-spray\", \"electrostatic spray\",\n        \"electrodeposition\", \"electrophoretic deposition (EPD)\",\n        \"chemical vapor deposition\", \"CVD coating\",\n        \"physical vapor deposition\", \"PVD coating\", \"sputtering\", \"evaporation\",\n        \"plasma treatment\", \"plasma polymerization\",\n        \"atomic layer deposition\", \"ALD\",\n        \"inkjet printing\",\n        \"roll-to-roll coating\",\n        \"microemulsion polymerization\",\n        \"in-situ polymerization\",\n        \"ultrasonic spray pyrolysis\"\n    ],\n    \n    'applications': [\n        \"protective coating\",\n        \"functional coating\",\n        \"smart coating\", \"intelligent coating\",\n        \"automotive coating\", \"automotive paint\", \"automotive sector\",\n        \"marine coating\", \"marine paint\", \"marine anti-fouling\",\n        \"architectural coating\", \"architectural paint\", \"civil construction\", \"building sector\",\n        \"aerospace coating\", \"aerospace sector\",\n        \"biomedical coating\", \"biomedical implants\", \"medical devices\",\n        \"electronic coating\", \"coating for electronics\", \"displays\",\n        \"textile coating\", \"smart textiles\",\n        \"packaging coating\", \"active packaging\",\n        \"optical coating\", \"lenses\",\n        \"energy applications\", \"solar cells\", \"batteries\", \"energy storage\",\n        \"catalysis\", \"catalysts\",\n        \"environmental remediation\", \"water purification\",\n        \"pipeline coating\",\n        \"wood coating\",\n        \"glass coating\"\n    ]\n}\n\n\n# Criar lista única de todas as palavras-chave\ntodas_palavras_chave = []\nfor categoria, palavras in PALAVRAS_CHAVE.items():\n    todas_palavras_chave.extend(palavras)\n\nprint(f\"🔍 Total de palavras-chave definidas: {len(todas_palavras_chave)}\")\nprint(f\"📂 Categorias: {list(PALAVRAS_CHAVE.keys())}\")",
      "block_group": "bf0480bb9d21495c9c769e8b1e1188f4",
      "execution_count": 106,
      "outputs": [
        {
          "name": "stdout",
          "text": "🔍 Total de palavras-chave definidas: 143\n📂 Categorias: ['main_terms', 'nano_materials', 'functional_properties', 'preparation_techniques', 'applications']\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d5bba769a0c340f99258db2f1551ca94",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 3. Funções Utilitárias\n\nFunções para filtro, busca e manipulação de dados.",
      "block_group": "6d7303de5f854e09afb1006497b2a47e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "3b428172",
        "execution_start": 1748389706280,
        "execution_millis": 0,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "2b63e84812314e8b93ba707eb0190ab6",
        "deepnote_cell_type": "code"
      },
      "source": "def filtrar_coluna(df, coluna, palavra, tipo=\"contem\"):\n    \"\"\"\n    Função auxiliar para filtrar uma dataframe com base em uma palavra-chave específica.\n\n    Parâmetros:\n    - df (DataFrame): DataFrame Pandas com os dados\n    - coluna (str): Nome da coluna a ser filtrada\n    - palavra (str): Palavra-chave usada para filtrar\n    - tipo (str): Método de filtro, opções: 'contem', 'igual'. Default é 'contem'.\n\n    Retorno:\n    - DataFrame contendo as linhas que correspondem ao filtro\n    \"\"\"\n    if tipo == \"contem\":\n        resultado = df[df[coluna].str.contains(palavra, case=False, na=False)]\n    elif tipo == \"igual\":\n        resultado = df[df[coluna].str.lower() == palavra.lower()]\n    else:\n        raise ValueError(\"Tipo de filtro não suportado. Use 'contem' ou 'igual'.\")\n\n    return resultado",
      "block_group": "3a960f469dd64c0dbefb55d61dcbd875",
      "execution_count": 109,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8a09f09331124c3c97d3c3b10b0e3aa1",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 4. Análise com Gemini AI\n\nFunções para análise automática de abstracts usando a API do Gemini.",
      "block_group": "1f6c6e439be54d538e5a29ef8a1f1d8b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "3a44aa35",
        "execution_start": 1748389709404,
        "execution_millis": 847500,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "f72abd9edae64664809e1e5fc54ad579",
        "deepnote_cell_type": "code"
      },
      "source": "# ...existing code...\n\ndef analisar_escopo_abstract(abstract_text):\n    \"\"\"\n    Analisa um abstract individual para determinar se se adequa ao escopo de nanorevestimentos e tintas\n    \"\"\"\n    if pd.isna(abstract_text) or str(abstract_text).strip() == '':\n        return \"Não se adequa - Abstract vazio ou não disponível\"\n    \n    model = genai.GenerativeModel('gemini-2.0-flash')\n    \n    prompt = f\"\"\"\n    Analise o seguinte abstract científico e determine se ele se adequa ao escopo de pesquisa sobre \"nanorevestimentos e tintas (nanocoatings and paints)\".\n\n    Abstract: {abstract_text}\n\n    Critérios para adequação ao escopo:\n    - Estudos sobre nanomateriais aplicados em revestimentos ou tintas\n    - Propriedades funcionais de nanocoatings (anticorrosão, antimicrobiano, autolimpante, etc.)\n    - Técnicas de preparação ou caracterização de nanorevestimentos\n    - Aplicações industriais de tintas nanoestruturadas\n    - Materiais nanoestruturados para proteção de superfícies\n\n    Responda APENAS uma das opções:\n    1. \"Sim - [breve justificativa]\"\n    2. \"Não - [breve justificativa explicando por que não se adequa]\"\n\n    Mantenha a justificativa concisa (máximo 100 palavras).\n    \"\"\"\n    \n    try:\n        response = model.generate_content(prompt)\n        return response.text.strip()\n    except Exception as e:\n        return f\"Erro na análise - {str(e)}\"\n\ndef processar_dataframe_escopo(df, coluna_abstract='Abstract', batch_size=10):\n    \"\"\"\n    Processa todo o DataFrame adicionando a coluna de adequação ao escopo\n    \"\"\"\n    # Verificar se a coluna Abstract existe\n    if coluna_abstract not in df.columns:\n        print(f\"Coluna '{coluna_abstract}' não encontrada no DataFrame\")\n        return df\n    \n    # Criar uma cópia do DataFrame\n    df_processado = df.copy()\n    \n    # Inicializar a nova coluna\n    df_processado['Se adequa ao escopo?'] = ''\n    \n    total_linhas = len(df_processado)\n    print(f\"Processando {total_linhas} abstracts...\")\n    \n    # Processar em lotes para evitar sobrecarga da API\n    for i in range(0, total_linhas, batch_size):\n        batch_end = min(i + batch_size, total_linhas)\n        print(f\"Processando linhas {i+1} a {batch_end}...\")\n        \n        for idx in range(i, batch_end):\n            abstract = df_processado.iloc[idx][coluna_abstract]\n            resultado = analisar_escopo_abstract(abstract)\n            df_processado.iloc[idx, df_processado.columns.get_loc('Se adequa ao escopo?')] = resultado\n            \n            # Mostrar progresso\n            if (idx + 1) % 5 == 0:\n                print(f\"  Processado: {idx + 1}/{total_linhas}\")\n        \n        # Pequena pausa entre lotes para não sobrecarregar a API\n        import time\n        time.sleep(2)\n    \n    return df_processado\n\n# Carregar o DataFrame\ndf = pd.read_csv('/work/ExtensaoemCienciadeDadosUece/Imersão - CenanoInk/Alan Delon.csv')\n\nprint(\"Informações do DataFrame:\")\nprint(f\"Total de linhas: {len(df)}\")\nprint(f\"Colunas disponíveis: {list(df.columns)}\")\n\n# Verificar se existe coluna Abstract\nif 'Abstract' in df.columns:\n    print(f\"Abstracts não vazios: {df['Abstract'].notna().sum()}\")\n    \n    # Processar apenas uma amostra primeiro (para teste)\n    print(\"\\n=== PROCESSAMENTO DE TESTE (primeiras 5 linhas) ===\")\n    df_teste = df.head(5).copy()\n    df_teste_processado = processar_dataframe_escopo(df_teste, batch_size=1)\n    \n    print(\"\\nResultados do teste:\")\n    for idx, row in df_teste_processado.iterrows():\n        print(f\"\\nLinha {idx + 1}:\")\n        print(f\"Título: {row.get('Article Title', 'N/A')[:100]}...\")\n        print(f\"Adequação: {row['Se adequa ao escopo?']}\")\n    \n    # Perguntar se deseja processar todo o DataFrame\n    resposta = input(\"\\nDeseja processar todo o DataFrame? (s/n): \")\n    if resposta.lower() == 's':\n        print(\"\\n=== PROCESSANDO TODO O DATAFRAME ===\")\n        df_completo = processar_dataframe_escopo(df)\n        \n        # Salvar resultado\n        arquivo_saida = 'df_com_analise_escopo.csv'\n        df_completo.to_csv(arquivo_saida, index=False)\n        print(f\"\\nResultados salvos em: {arquivo_saida}\")\n        \n        # Mostrar estatísticas\n        adequados = df_completo['Se adequa ao escopo?'].str.contains('Sim', case=False, na=False).sum()\n        nao_adequados = df_completo['Se adequa ao escopo?'].str.contains('Não', case=False, na=False).sum()\n        \n        print(f\"\\n=== ESTATÍSTICAS FINAIS ===\")\n        print(f\"Adequados ao escopo: {adequados}\")\n        print(f\"Não adequados ao escopo: {nao_adequados}\")\n        print(f\"Total processado: {adequados + nao_adequados}\")\n        \nelse:\n    print(\"Coluna 'Abstract' não encontrada no DataFrame\")\n    print(\"Colunas disponíveis:\", list(df.columns))",
      "block_group": "ab3dcba9461f46b980b51b4101a4dfab",
      "execution_count": 112,
      "outputs": [
        {
          "name": "stdout",
          "text": "Informações do DataFrame:\nTotal de linhas: 525\nColunas disponíveis: ['Publication Type', 'Authors', 'Book Authors', 'Book Editors', 'Book Group Authors', 'Author Full Names', 'Book Author Full Names', 'Group Authors', 'Article Title', 'Source Title', 'Book Series Title', 'Book Series Subtitle', 'Language', 'Document Type', 'Conference Title', 'Conference Date', 'Conference Location', 'Conference Sponsor', 'Conference Host', 'Author Keywords', 'Keywords Plus', 'Abstract', 'Addresses', 'Affiliations', 'Reprint Addresses', 'Email Addresses', 'Researcher Ids', 'ORCIDs', 'Funding Orgs', 'Funding Name Preferred', 'Funding Text', 'Cited References', 'Cited Reference Count', 'Times Cited, WoS Core', 'Times Cited, All Databases', '180 Day Usage Count', 'Since 2013 Usage Count', 'Publisher', 'Publisher City', 'Publisher Address', 'ISSN', 'eISSN', 'ISBN', 'Journal Abbreviation', 'Journal ISO Abbreviation', 'Publication Date', 'Publication Year', 'Volume', 'Issue', 'Part Number', 'Supplement', 'Special Issue', 'Meeting Abstract', 'Start Page', 'End Page', 'Article Number', 'DOI', 'DOI Link', 'Book DOI', 'Early Access Date', 'Number of Pages', 'WoS Categories', 'Web of Science Index', 'Research Areas', 'IDS Number', 'Pubmed Id', 'Open Access Designations', 'Highly Cited Status', 'Hot Paper Status', 'Date of Export', 'UT (Unique WOS ID)', 'Web of Science Record', 'Unnamed: 72']\nAbstracts não vazios: 525\n\n=== PROCESSAMENTO DE TESTE (primeiras 5 linhas) ===\nProcessando 5 abstracts...\nProcessando linhas 1 a 1...\nProcessando linhas 2 a 2...\nProcessando linhas 3 a 3...\nProcessando linhas 4 a 4...\nProcessando linhas 5 a 5...\n  Processado: 5/5\n\nResultados do teste:\n\nLinha 1:\nTítulo: Ab Initio Study of the Atomic Level Structure of the Rutile TiO2(110) -Titanium Nitride (TiN) Interf...\nAdequação: Sim - O abstract descreve um estudo teórico (DFT) sobre a interface TiO2/TiN, que é relevante para nanorrevestimentos devido às propriedades protetoras do TiN e à formação espontânea de uma camada de óxido (TiO2). A investigação das propriedades estruturais e eletrônicas da interface, incluindo defeitos e não-estequiometria, contribui para a compreensão e otimização de nanorrevestimentos à base de TiN.\n\nLinha 2:\nTítulo: Polymer and ceramic nanocomposites for aerospace applications...\nAdequação: Não - O abstract discute nanocompósitos de matriz polimérica e cerâmica para aplicações aeroespaciais em geral (estruturas, blindagem eletromagnética, etc.), mas não foca especificamente em nanorrevestimentos ou tintas, suas propriedades funcionais, técnicas de preparação/caracterização ou aplicações industriais de tintas nanoestruturadas. A menção a \"coating\" é muito genérica dentro do contexto mais amplo de aplicações estruturais.\n\nLinha 3:\nTítulo: Recycling of yttria-stabilized zirconia waste powders in glazes suitable for ceramic tiles...\nAdequação: 2. \"Não - O abstract descreve a reciclagem de resíduos de zircônia estabilizada com ítria para a produção de fritas para esmaltes e cerâmicas. Embora a zircônia estabilizada possa ser usada em nanorrevestimentos, o abstract não menciona a escala nanométrica, a aplicação como revestimento fino, ou propriedades funcionais típicas de nanorrevestimentos (anticorrosão, etc.). O foco é na produção de material cerâmico em escala macroscópica.\"\n\nLinha 4:\nTítulo: Properties of Polysiloxane Coated Borosilicate Lining Blocks...\nAdequação: 1. Sim - O abstract descreve a aplicação de uma mistura de sílica fumada (que pode conter nanopartículas) e polissiloxano como revestimento para melhorar a resistência térmica de um bloco de borosilicato. A técnica de preparação e caracterização (microscopia, XRD, TGA-DTA) se encaixa nos critérios, e a aplicação do revestimento para proteção da superfície também.\n\nLinha 5:\nTítulo: Solution Processed Porous Fe2O3 Thin Films for Solar-Driven Water Splitting...\nAdequação: Não - O abstract descreve a produção e caracterização de filmes finos de hematita (α-Fe2O3) para aplicação em divisão de água fotossensibilizada. Embora envolva um nanomaterial (hematita) e um filme fino, o foco principal é na sua aplicação em células solares para produção de hidrogênio, e não em propriedades de revestimento, tintas, proteção de superfícies ou aplicações industriais relevantes ao escopo definido.\n\n=== PROCESSANDO TODO O DATAFRAME ===\nProcessando 525 abstracts...\nProcessando linhas 1 a 10...\n  Processado: 5/525\n  Processado: 10/525\nProcessando linhas 11 a 20...\n  Processado: 15/525\n  Processado: 20/525\nProcessando linhas 21 a 30...\n  Processado: 25/525\n  Processado: 30/525\nProcessando linhas 31 a 40...\n  Processado: 35/525\n  Processado: 40/525\nProcessando linhas 41 a 50...\n  Processado: 45/525\n  Processado: 50/525\nProcessando linhas 51 a 60...\n  Processado: 55/525\n  Processado: 60/525\nProcessando linhas 61 a 70...\n  Processado: 65/525\n  Processado: 70/525\nProcessando linhas 71 a 80...\n  Processado: 75/525\n  Processado: 80/525\nProcessando linhas 81 a 90...\n  Processado: 85/525\n  Processado: 90/525\nProcessando linhas 91 a 100...\n  Processado: 95/525\n  Processado: 100/525\nProcessando linhas 101 a 110...\n  Processado: 105/525\n  Processado: 110/525\nProcessando linhas 111 a 120...\n  Processado: 115/525\n  Processado: 120/525\nProcessando linhas 121 a 130...\n  Processado: 125/525\n  Processado: 130/525\nProcessando linhas 131 a 140...\n  Processado: 135/525\n  Processado: 140/525\nProcessando linhas 141 a 150...\n  Processado: 145/525\n  Processado: 150/525\nProcessando linhas 151 a 160...\n  Processado: 155/525\n  Processado: 160/525\nProcessando linhas 161 a 170...\n  Processado: 165/525\n  Processado: 170/525\nProcessando linhas 171 a 180...\n  Processado: 175/525\n  Processado: 180/525\nProcessando linhas 181 a 190...\n  Processado: 185/525\n  Processado: 190/525\nProcessando linhas 191 a 200...\n  Processado: 195/525\n  Processado: 200/525\nProcessando linhas 201 a 210...\n  Processado: 205/525\n  Processado: 210/525\nProcessando linhas 211 a 220...\n  Processado: 215/525\n  Processado: 220/525\nProcessando linhas 221 a 230...\n  Processado: 225/525\n  Processado: 230/525\nProcessando linhas 231 a 240...\n  Processado: 235/525\n  Processado: 240/525\nProcessando linhas 241 a 250...\n  Processado: 245/525\n  Processado: 250/525\nProcessando linhas 251 a 260...\n  Processado: 255/525\n  Processado: 260/525\nProcessando linhas 261 a 270...\n  Processado: 265/525\n  Processado: 270/525\nProcessando linhas 271 a 280...\n  Processado: 275/525\n  Processado: 280/525\nProcessando linhas 281 a 290...\n  Processado: 285/525\n  Processado: 290/525\nProcessando linhas 291 a 300...\n  Processado: 295/525\n  Processado: 300/525\nProcessando linhas 301 a 310...\n  Processado: 305/525\n  Processado: 310/525\nProcessando linhas 311 a 320...\n  Processado: 315/525\n  Processado: 320/525\nProcessando linhas 321 a 330...\n  Processado: 325/525\n  Processado: 330/525\nProcessando linhas 331 a 340...\n  Processado: 335/525\n  Processado: 340/525\nProcessando linhas 341 a 350...\n  Processado: 345/525\n  Processado: 350/525\nProcessando linhas 351 a 360...\n  Processado: 355/525\n  Processado: 360/525\nProcessando linhas 361 a 370...\n  Processado: 365/525\n  Processado: 370/525\nProcessando linhas 371 a 380...\n  Processado: 375/525\n  Processado: 380/525\nProcessando linhas 381 a 390...\n  Processado: 385/525\n  Processado: 390/525\nProcessando linhas 391 a 400...\n  Processado: 395/525\n  Processado: 400/525\nProcessando linhas 401 a 410...\n  Processado: 405/525\n  Processado: 410/525\nProcessando linhas 411 a 420...\n  Processado: 415/525\n  Processado: 420/525\nProcessando linhas 421 a 430...\n  Processado: 425/525\n  Processado: 430/525\nProcessando linhas 431 a 440...\n  Processado: 435/525\n  Processado: 440/525\nProcessando linhas 441 a 450...\n  Processado: 445/525\n  Processado: 450/525\nProcessando linhas 451 a 460...\n  Processado: 455/525\n  Processado: 460/525\nProcessando linhas 461 a 470...\n  Processado: 465/525\n  Processado: 470/525\nProcessando linhas 471 a 480...\n  Processado: 475/525\n  Processado: 480/525\nProcessando linhas 481 a 490...\n  Processado: 485/525\n  Processado: 490/525\nProcessando linhas 491 a 500...\n  Processado: 495/525\n  Processado: 500/525\nProcessando linhas 501 a 510...\n  Processado: 505/525\n  Processado: 510/525\nProcessando linhas 511 a 520...\n  Processado: 515/525\n  Processado: 520/525\nProcessando linhas 521 a 525...\n  Processado: 525/525\n\nResultados salvos em: df_com_analise_escopo.csv\n\n=== ESTATÍSTICAS FINAIS ===\nAdequados ao escopo: 231\nNão adequados ao escopo: 405\nTotal processado: 636\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9eee10dcfba1467d8b83fef58d192181",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 5. Processamento em Lote\n\nFunções para processar grandes volumes de dados respeitando rate limits.",
      "block_group": "3a4a7229dc854d46af36dd96c7738edd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "46887e56",
        "execution_start": 1748390945236,
        "execution_millis": 0,
        "execution_context_id": "eae68ee2-77cf-4c30-baae-a4f6d41ee4f1",
        "cell_id": "6e8d81de55474eb5b5c808a167db3ad4",
        "deepnote_cell_type": "code"
      },
      "source": "import pandas as pd\nimport random\nimport time\nfrom typing import List\n\n# Fixing imports and cleaning up erroneous duplicated or corrupted lines in the code.\ndef analisar_escopo_abstract(abstract_text: str, retry_count: int = 3) -> str:\n    \"\"\"\n    Analisa um abstract individual para determinar se se adequa ao escopo de nanorevestimentos e tintas usando Gemini 2.0 Flash-Lite.\n\n    Args:\n        abstract_text: Texto do abstract.\n        retry_count: Número de tentativas em caso de erro.\n\n    Returns:\n        String com resultado da análise.\n    \"\"\"\n    if pd.isna(abstract_text) or str(abstract_text).strip() == '':\n        return \"Não se adequa - Abstract vazio ou não disponível\"\n\n    # Placeholder for initializing the model\n    try:\n        model = genai.GenerativeModel(CONFIG['modelo_gemini'])\n    except NameError:\n        raise Exception(\"CONFIG or genai module not properly configured\")\n\n    prompt = f\"\"\"\n    Analise o seguinte abstract científico e determine se ele se adequa ao escopo de pesquisa sobre \"nanorevestimentos e tintas (nanocoatings and paints)\".\n\n    Abstract: {abstract_text}\n\n    Critérios para adequação ao escopo:\n        - Materiais nanoestruturados para proteção de superfícies\n        - Estudos sobre nanomateriais aplicados em revestimentos ou tintas\n        - Propriedades funcionais de nanocoatings (anticorrosão, antimicrobiano, autolimpante, etc.)\n        - Técnicas de preparação ou caracterização de nanorevestimentos\n        - Aplicações industriais de tintas nanoestruturadas\n\n    Responda APENAS uma das opções:\n        1. \"Sim - [breve justificativa]\"\n        2. \"Não - [breve justificativa explicando por que não se adequa]\"\n\n    Mantenha a justificativa concisa (máximo 100 palavras).\n    \"\"\"\n\n    for attempt in range(retry_count):\n        try:\n            response = model.generate_content(prompt)\n            return response.text.strip()\n        except Exception as e:\n            error_msg = str(e)\n            if \"429\" in error_msg or \"quota\" in error_msg.lower():\n                if attempt < retry_count - 1:\n                    wait_time = 3 + random.randint(1, 2)\n                    print(f\"  ⏳ Rate limit - aguardando {wait_time}s...\")\n                    time.sleep(wait_time)\n                    continue\n                else:\n                    return f\"Erro - Rate limit excedido após {retry_count} tentativas\"\n            return f\"Erro na análise - {error_msg}\"\n\n    return \"Erro - Falha após múltiplas tentativas\"",
      "block_group": "0abc433754b44dba8763ce3e02066b69",
      "execution_count": 1,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "99bbfdbfe8e7432e9241a937d2ecc8d1",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 6. Execução Principal\n\nScript principal para carregar dados e executar análises.",
      "block_group": "80483a10bb7f4b5abde919f31eaaa694"
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "54f788e0",
        "execution_start": 1748388711972,
        "execution_millis": 388,
        "execution_context_id": "3ed297e7-a555-43b2-887a-b28769104494",
        "cell_id": "3fd24c99c5944d339e143f1b21acf3aa",
        "deepnote_cell_type": "code"
      },
      "source": "# Carregar e explorar os dados\nprint(\"📂 Carregando dados...\")\n\ntry:\n    df = pd.read_csv(\"/work/ExtensaoemCienciadeDadosUece/Imersão - CenanoInk/Alan Delon.csv\")\n    print(f\"✅ Dados carregados com sucesso\")\n    print(f\"📊 Total de linhas: {len(df):,}\")\n    print(f\"📊 Total de colunas: {len(df.columns)}\")\n    print(f\"📋 Colunas disponíveis: {list(df.columns)}\")\n    \n    # Verificar colunas essenciais\n    colunas_essenciais = ['Article Title', 'Abstract']\n    colunas_encontradas = [col for col in colunas_essenciais if col in df.columns]\n    colunas_faltantes = [col for col in colunas_essenciais if col not in df.columns]\n    \n    print(f\"\\n✅ Colunas encontradas: {colunas_encontradas}\")\n    if colunas_faltantes:\n        print(f\"⚠️ Colunas faltantes: {colunas_faltantes}\")\n    \n    # Estatísticas dos abstracts\n    if 'Abstract' in df.columns:\n        abstracts_validos = df['Abstract'].notna().sum()\n        abstracts_vazios = df['Abstract'].isna().sum()\n        print(f\"\\n📄 Abstracts disponíveis: {abstracts_validos:,}\")\n        print(f\"📄 Abstracts vazios: {abstracts_vazios:,}\")\n        print(f\"📄 Taxa de completude: {(abstracts_validos/len(df))*100:.1f}%\")\n    \nexcept FileNotFoundError:\n    print(f\"❌ Arquivo não encontrado: {CONFIG['arquivo_entrada']}\")\n    df = None\nexcept Exception as e:\n    print(f\"❌ Erro ao carregar dados: {e}\")\n    df = None",
      "block_group": "c9d85e9fcf374491a8a22b116c00ba31",
      "execution_count": 82,
      "outputs": [
        {
          "name": "stdout",
          "text": "📂 Carregando dados...\n✅ Dados carregados com sucesso\n📊 Total de linhas: 525\n📊 Total de colunas: 73\n📋 Colunas disponíveis: ['Publication Type', 'Authors', 'Book Authors', 'Book Editors', 'Book Group Authors', 'Author Full Names', 'Book Author Full Names', 'Group Authors', 'Article Title', 'Source Title', 'Book Series Title', 'Book Series Subtitle', 'Language', 'Document Type', 'Conference Title', 'Conference Date', 'Conference Location', 'Conference Sponsor', 'Conference Host', 'Author Keywords', 'Keywords Plus', 'Abstract', 'Addresses', 'Affiliations', 'Reprint Addresses', 'Email Addresses', 'Researcher Ids', 'ORCIDs', 'Funding Orgs', 'Funding Name Preferred', 'Funding Text', 'Cited References', 'Cited Reference Count', 'Times Cited, WoS Core', 'Times Cited, All Databases', '180 Day Usage Count', 'Since 2013 Usage Count', 'Publisher', 'Publisher City', 'Publisher Address', 'ISSN', 'eISSN', 'ISBN', 'Journal Abbreviation', 'Journal ISO Abbreviation', 'Publication Date', 'Publication Year', 'Volume', 'Issue', 'Part Number', 'Supplement', 'Special Issue', 'Meeting Abstract', 'Start Page', 'End Page', 'Article Number', 'DOI', 'DOI Link', 'Book DOI', 'Early Access Date', 'Number of Pages', 'WoS Categories', 'Web of Science Index', 'Research Areas', 'IDS Number', 'Pubmed Id', 'Open Access Designations', 'Highly Cited Status', 'Hot Paper Status', 'Date of Export', 'UT (Unique WOS ID)', 'Web of Science Record', 'Unnamed: 72']\n\n✅ Colunas encontradas: ['Article Title', 'Abstract']\n\n📄 Abstracts disponíveis: 525\n📄 Abstracts vazios: 0\n📄 Taxa de completude: 100.0%\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "88037aed",
        "execution_start": 1748390947928,
        "execution_millis": 2,
        "execution_context_id": "eae68ee2-77cf-4c30-baae-a4f6d41ee4f1",
        "cell_id": "e258f6ef43e04dfa994d4ea4f2329c12",
        "deepnote_cell_type": "code"
      },
      "source": "def buscar_artigos_por_palavras_chave(df, palavras_chave):\n    \"\"\"\n    Filtra os artigos em um DataFrame com base em uma lista de palavras-chave.\n\n    Args:\n        df (pd.DataFrame): DataFrame contendo os artigos.\n        palavras_chave (List[str]): Lista de palavras-chave para buscar nos abstracts ou títulos.\n\n    Returns:\n        pd.DataFrame: DataFrame com os artigos que contêm as palavras-chave.\n    \"\"\"\n    if 'Abstract' not in df.columns or 'Article Title' not in df.columns:\n        raise ValueError(\"O DataFrame deve conter as colunas 'Abstract' e 'Article Title'\")\n\n    # Criar um filtro para verificar se as palavras-chave aparecem no título ou resumo\n    filtro = (df['Abstract'].str.contains('|'.join(palavras_chave), case=False, na=False) |\n              df['Article Title'].str.contains('|'.join(palavras_chave), case=False, na=False))\n\n    # Aplicar o filtro ao DataFrame\n    return df[filtro].copy()",
      "block_group": "067684ac8e464eee9758df17b12bcbcd",
      "execution_count": 4,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "d7544e9e",
        "execution_start": 1748390947976,
        "execution_millis": 0,
        "execution_context_id": "eae68ee2-77cf-4c30-baae-a4f6d41ee4f1",
        "cell_id": "623e8051c39544feac26910eb7d09406",
        "deepnote_cell_type": "code"
      },
      "source": "def processar_com_checkpoint(df, checkpoint_file='checkpoint.csv', batch_size=10):\n    \"\"\"\n    Processa o DataFrame em lotes e salva checkpoints em um arquivo CSV intermediário para recuperação.\n\n    Args:\n        df (pd.DataFrame): DataFrame a ser processado.\n        checkpoint_file (str): Nome do arquivo de checkpoint.\n        batch_size (int): Número de linhas a serem processadas por lote.\n\n    Returns:\n        pd.DataFrame: DataFrame com os resultados do processamento.\n    \"\"\"\n    import os\n    import pandas as pd\n\n    # Carregar checkpoint se já existir\n    if os.path.exists(checkpoint_file):\n        df_checkpoint = pd.read_csv(checkpoint_file)\n        processed_ids = set(df_checkpoint['ID'])\n        print(f\"🔄 Checkpoint encontrado. {len(processed_ids):,} linhas já processadas.\")\n    else:\n        df_checkpoint = pd.DataFrame()\n        processed_ids = set()\n\n    # Identificar IDs a processar\n    df['ID'] = df.index  # Garantir uma coluna ID única\n    to_process = df[~df['ID'].isin(processed_ids)]\n\n    print(f\"🚀 Iniciando processamento com checkpoint...\")\n    total = len(to_process)\n\n    for start in range(0, total, batch_size):\n        end = min(start + batch_size, total)\n        batch = to_process.iloc[start:end]\n        print(f\"🔬 Processando linhas {start + 1} a {end}/{total}...\")\n\n        # Executar análise lotes\n        batch['Se adequa ao escopo?'] = batch['Abstract'].apply(analisar_escopo_abstract)\n\n        # Adicionar ao checkpoint\n        df_checkpoint = pd.concat([df_checkpoint, batch], ignore_index=True)\n\n        # Salvar checkpoint\n        df_checkpoint.to_csv(checkpoint_file, index=False)\n\n        print(f\"✔️ Checkpoint salvo: {checkpoint_file}\")\n\n    print(\"✅ Processamento concluído.\")\n    return df_checkpoint",
      "block_group": "554fe6e7cd474ea5b608553debd06248",
      "execution_count": 5,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd6f7c35177049a0a2f878501e039b53",
        "deepnote_cell_type": "markdown"
      },
      "source": "## 7. Conclusão\n\n### Funcionalidades implementadas:\n\n1. ✅ **Busca por palavras-chave**: Sistema robusto de filtro com múltiplas categorias\n2. ✅ **Análise com Gemini AI**: Análise automática de relevância dos abstracts\n3. ✅ **Rate limiting**: Respeita limites da API (30 req/min, 1.500 req/dia)\n4. ✅ **Sistema de checkpoint**: Permite retomar análises interrompidas\n5. ✅ **Estatísticas detalhadas**: Métricas de adequação e performance\n6. ✅ **Exportação de dados**: Salva resultados em formato CSV\n\n### Arquivos gerados:\n- `artigos_nanorevestimentos_encontrados.csv`: Artigos filtrados por palavras-chave\n- `analise_escopo_checkpoint.csv`: Checkpoint do processamento\n- `df_com_analise_escopo_completo.csv`: Análise completa com Gemini\n\n### Próximos passos:\n- Refinar palavras-chave com base nos resultados\n- Implementar análise de trends temporais\n- Adicionar análise de colaborações e redes\n- Desenvolver dashboard interativo",
      "block_group": "b72e5ebeb21345c19e82e19c1d0c9a2b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "25ed2e8d72ce4894b6c49899bfc50450",
        "deepnote_cell_type": "code"
      },
      "source": "# Adicionar ao final da célula de configurações (após CONFIG)\n# Configuração da API do Gemini\ngenai.configure(api_key='AIzaSyA_wEQ0XgcJNy9Yw58sH94VBeI14mpH9b0')\n\nprint(\"✅ Dependências carregadas e API configurada\")\n# Dicionário de nanomateriais organizados por categoria\nNANOMATERIAIS = {\n    'oxidos_metalicos': [\n        'TiO2', 'titanium dioxide', 'titanium oxide',\n        'ZnO', 'zinc oxide',\n        'Al2O3', 'alumina', 'aluminum oxide', 'aluminium oxide',\n        'Fe2O3', 'iron oxide', 'ferric oxide',\n        'CeO2', 'cerium oxide', 'ceria',\n        'SiO2', 'silica', 'silicon dioxide',\n        'Cr2O3', 'chromium oxide',\n        'NiO', 'nickel oxide',\n        'CuO', 'copper oxide',\n        'MgO', 'magnesium oxide',\n        'SnO2', 'tin oxide'\n    ],\n    \n    'nanoparticulas_metalicas': [\n        'silver nanoparticle', 'Ag nanoparticle', 'nano-Ag', 'AgNP',\n        'gold nanoparticle', 'Au nanoparticle', 'nano-Au', 'AuNP',\n        'copper nanoparticle', 'Cu nanoparticle', 'nano-Cu', 'CuNP',\n        'zinc nanoparticle', 'Zn nanoparticle', 'nano-Zn', 'ZnNP',\n        'iron nanoparticle', 'Fe nanoparticle', 'nano-Fe', 'FeNP'\n    ],\n    \n    'nanomateriais_carbono': [\n        'carbon nanotube', 'CNT', 'MWCNT', 'SWCNT',\n        'multi-walled carbon nanotube', 'single-walled carbon nanotube',\n        'graphene', 'graphene oxide', 'GO', 'reduced graphene oxide', 'rGO',\n        'carbon nanofiber', 'CNF',\n        'fullerene', 'C60', 'carbon black',\n        'graphene nanoplatelets', 'GNP'\n    ],\n    \n    'nanoclay_silicatos': [\n        'montmorillonite', 'MMT',\n        'halloysite nanotube', 'HNT',\n        'laponite', 'bentonite',\n        'kaolinite', 'vermiculite',\n        'clay nanoparticle', 'nanoclay',\n        'organoclay', 'modified clay'\n    ],\n    \n    'nanocompositos_polimericos': [\n        'polymer nanocomposite', 'nanocomposite polymer',\n        'PMMA nanocomposite', 'epoxy nanocomposite',\n        'polyurethane nanocomposite', 'PU nanocomposite',\n        'acrylic nanocomposite', 'latex nanocomposite'\n    ],\n    \n    'quantum_dots': [\n        'quantum dot', 'QD', 'CdSe', 'CdS', 'ZnS',\n        'InAs', 'InP', 'PbS', 'PbSe',\n        'semiconductor nanocrystal'\n    ],\n    \n    'outros_nanomateriais': [\n        'mesoporous silica', 'MCM-41', 'SBA-15',\n        'hydroxyapatite', 'HAp', 'nano-HAp',\n        'calcium carbonate', 'CaCO3', 'nano-CaCO3',\n        'boehmite', 'gibbsite',\n        'cellulose nanofiber', 'CNF', 'nanocellulose',\n        'chitin nanoparticle', 'chitosan nanoparticle'\n    ]\n}\n\n# Criar lista única de todos os nanomateriais\ntodos_nanomateriais = []\nfor categoria, materiais in NANOMATERIAIS.items():\n    todos_nanomateriais.extend(materiais)\n\nprint(f\"🔬 Total de nanomateriais catalogados: {len(todos_nanomateriais)}\")\nprint(f\"📂 Categorias de nanomateriais: {list(NANOMATERIAIS.keys())}\")\n\ndef identificar_nanomateriais_abstract(abstract_text: str, use_gemini: bool = True) -> str:\n    \"\"\"\n    Identifica nanomateriais mencionados no abstract usando busca por palavras-chave + Gemini AI\n    \n    Args:\n        abstract_text: Texto do abstract\n        use_gemini: Se True, usa Gemini para confirmação e extração adicional\n    \n    Returns:\n        String com nanomateriais identificados separados por vírgula\n    \"\"\"\n    if pd.isna(abstract_text) or str(abstract_text).strip() == '':\n        return \"Não identificado - Abstract vazio\"\n    \n    abstract_lower = str(abstract_text).lower()\n    materiais_encontrados = set()\n    \n    # Busca por palavras-chave\n    print(\"🔍 Buscando por palavras-chave...\")\n    for categoria, materiais in NANOMATERIAIS.items():\n        for material in materiais:\n            if material.lower() in abstract_lower:\n                materiais_encontrados.add(material)\n                print(f\"  ✓ Encontrado: {material} (categoria: {categoria})\")\n    \n    # Se usar Gemini para confirmação e busca adicional\n    if use_gemini:\n        try:\n            model = genai.GenerativeModel(CONFIG['modelo_gemini'])\n            \n            prompt = f\"\"\"\n            Analise o seguinte abstract científico e identifique TODOS os nanomateriais mencionados.\n\n            Abstract: {abstract_text}\n\n            Instruções:\n            1. Identifique nanomateriais, nanopartículas, nanoestruturas mencionadas\n            2. Inclua óxidos metálicos (TiO2, ZnO, etc.), nanopartículas metálicas, nanomateriais de carbono\n            3. Inclua materiais com prefixo \"nano-\" ou sufixo \"nanoparticle\"\n            4. Liste APENAS os nomes dos materiais, separados por vírgula\n            5. Use nomenclatura padrão (ex: TiO2, não \"dióxido de titânio\")\n            6. Se não encontrar nanomateriais, responda \"Nenhum nanomaterial específico identificado\"\n\n            Exemplos de resposta:\n            - \"TiO2, ZnO, silver nanoparticles\"\n            - \"graphene oxide, carbon nanotubes\"\n            - \"Nenhum nanomaterial específico identificado\"\n\n            Resposta:\n            \"\"\"\n            \n            response = model.generate_content(prompt)\n            gemini_result = response.text.strip()\n            \n            # Processar resultado do Gemini\n            if \"nenhum\" not in gemini_result.lower():\n                gemini_materiais = [m.strip() for m in gemini_result.split(',')]\n                materiais_encontrados.update(gemini_materiais)\n                print(f\"  🤖 Gemini encontrou: {gemini_materiais}\")\n            \n        except Exception as e:\n            print(f\"  ⚠️ Erro no Gemini: {e}\")\n    \n    # Preparar resultado final\n    if materiais_encontrados:\n        resultado = ', '.join(sorted(materiais_encontrados))\n        print(f\"  📋 Resultado final: {resultado}\")\n        return resultado\n    else:\n        return \"Nenhum nanomaterial específico identificado\"\n\ndef processar_nanomateriais_dataframe(df: pd.DataFrame, \n                                     coluna_abstract: str = 'Abstract',\n                                     use_gemini: bool = True,\n                                     batch_size: int = 10) -> pd.DataFrame:\n    \"\"\"\n    Processa DataFrame completo identificando nanomateriais\n    \n    Args:\n        df: DataFrame a ser processado\n        coluna_abstract: Nome da coluna com abstracts\n        use_gemini: Se usar Gemini AI para análise\n        batch_size: Tamanho do lote para processamento\n    \n    Returns:\n        DataFrame com nova coluna 'Nanomaterial Citado'\n    \"\"\"\n    if coluna_abstract not in df.columns:\n        print(f\"❌ Coluna '{coluna_abstract}' não encontrada\")\n        return df\n    \n    df_processado = df.copy()\n    df_processado['Nanomaterial Citado'] = ''\n    \n    total_linhas = len(df_processado)\n    print(f\"📋 Processando {total_linhas} abstracts para identificação de nanomateriais...\")\n    \n    if use_gemini:\n        print(f\"⚠️ Usando Gemini AI - Limite: {CONFIG['max_requests_per_day']} req/dia\")\n        if total_linhas > CONFIG['max_requests_per_day']:\n            print(f\"⚠️ Dataset tem {total_linhas} linhas, limite diário: {CONFIG['max_requests_per_day']}\")\n            resposta = input(f\"Processar apenas as primeiras {CONFIG['max_requests_per_day']} linhas? (s/n): \")\n            if resposta.lower() == 's':\n                total_linhas = CONFIG['max_requests_per_day']\n            else:\n                print(\"❌ Processamento cancelado\")\n                return df_processado\n    \n    requests_made = 0\n    start_time = time.time()\n    \n    for idx in range(total_linhas):\n        # Controle de rate limit se usando Gemini\n        if use_gemini:\n            elapsed_time = time.time() - start_time\n            if requests_made >= (CONFIG['max_requests_per_minute'] - 1) and elapsed_time < 60:\n                wait_time = 60 - elapsed_time + 2\n                print(f\"\\n⏳ Rate limit: aguardando {wait_time:.1f}s...\")\n                time.sleep(wait_time)\n                requests_made = 0\n                start_time = time.time()\n        \n        abstract = df_processado.iloc[idx][coluna_abstract]\n        \n        # Progresso\n        if idx % 10 == 0 or idx == total_linhas - 1:\n            print(f\"📊 Processando {idx + 1}/{total_linhas} ({((idx + 1)/total_linhas)*100:.1f}%)\")\n        \n        resultado = identificar_nanomateriais_abstract(abstract, use_gemini=use_gemini)\n        df_processado.iloc[idx, df_processado.columns.get_loc('Nanomaterial Citado')] = resultado\n        \n        if use_gemini:\n            requests_made += 1\n            time.sleep(CONFIG['delay_between_requests'])\n    \n    return df_processado\n\ndef analisar_nanomateriais_com_estatisticas(df: pd.DataFrame) -> dict:\n    \"\"\"\n    Analisa os nanomateriais identificados e gera estatísticas\n    \n    Args:\n        df: DataFrame com coluna 'Nanomaterial Citado'\n    \n    Returns:\n        Dicionário com estatísticas dos nanomateriais\n    \"\"\"\n    if 'Nanomaterial Citado' not in df.columns:\n        return {\"erro\": \"Coluna 'Nanomaterial Citado' não encontrada\"}\n    \n    # Coletar todos os nanomateriais mencionados\n    todos_materiais = []\n    for materiais_str in df['Nanomaterial Citado'].dropna():\n        if materiais_str and \"nenhum\" not in materiais_str.lower():\n            materiais = [m.strip() for m in materiais_str.split(',')]\n            todos_materiais.extend(materiais)\n    \n    # Contar frequências\n    from collections import Counter\n    contador_materiais = Counter(todos_materiais)\n    \n    # Categorizar materiais\n    materiais_por_categoria = {}\n    for categoria, lista_materiais in NANOMATERIAIS.items():\n        materiais_categoria = []\n        for material in contador_materiais:\n            if any(mat.lower() in material.lower() for mat in lista_materiais):\n                materiais_categoria.append((material, contador_materiais[material]))\n        if materiais_categoria:\n            materiais_por_categoria[categoria] = sorted(materiais_categoria, key=lambda x: x[1], reverse=True)\n    \n    # Estatísticas gerais\n    total_artigos = len(df)\n    artigos_com_nanomateriais = len(df[df['Nanomaterial Citado'].str.contains('TiO2|ZnO|graphene|nanotube|nanoparticle', case=False, na=False)])\n    \n    return {\n        'total_artigos': total_artigos,\n        'artigos_com_nanomateriais': artigos_com_nanomateriais,\n        'taxa_identificacao': (artigos_com_nanomateriais / total_artigos) * 100,\n        'materiais_mais_citados': contador_materiais.most_common(10),\n        'materiais_por_categoria': materiais_por_categoria,\n        'total_materiais_unicos': len(contador_materiais)\n    }\n\n# Exemplo de uso\nprint(\"\\n\" + \"=\"*60)\nprint(\"🔬 IDENTIFICAÇÃO DE NANOMATERIAIS\")\nprint(\"=\"*60)\n\n# Carregar dados se ainda não carregado\nif 'df' not in locals() or df is None:\n    try:\n        df = pd.read_csv(CONFIG['arquivo_entrada'])\n        print(f\"📂 Dados carregados: {len(df)} artigos\")\n    except:\n        print(\"❌ Erro ao carregar dados\")\n        df = None\n\nif df is not None and 'Abstract' in df.columns:\n    # Teste com poucos abstracts primeiro\n    print(f\"\\n🧪 TESTE DE IDENTIFICAÇÃO (primeiros 3 abstracts)\")\n    df_teste = df.head(3).copy()\n    \n    # Testar sem Gemini primeiro (mais rápido)\n    print(\"\\n📋 Teste 1: Apenas busca por palavras-chave\")\n    for idx, row in df_teste.iterrows():\n        abstract = row['Abstract']\n        resultado = identificar_nanomateriais_abstract(abstract, use_gemini=False)\n        print(f\"\\nArtigo {idx+1}:\")\n        print(f\"Título: {row['Article Title'][:60]}...\")\n        print(f\"Nanomateriais: {resultado}\")\n    \n    # Perguntar se deseja usar Gemini\n    resposta_gemini = input(\"\\nUsar Gemini AI para análise mais precisa? (s/n): \")\n    use_gemini = resposta_gemini.lower() == 's'\n    \n    if use_gemini:\n        print(f\"\\n🤖 Teste 2: Com Gemini AI\")\n        for idx, row in df_teste.iterrows():\n            abstract = row['Abstract']\n            resultado = identificar_nanomateriais_abstract(abstract, use_gemini=True)\n            print(f\"\\nArtigo {idx+1} (com Gemini):\")\n            print(f\"Nanomateriais: {resultado}\")\n    \n    # Perguntar sobre processamento completo\n    resposta_completo = input(f\"\\nProcessar todo o dataset ({len(df)} artigos)? (s/n): \")\n    \n    if resposta_completo.lower() == 's':\n        print(f\"\\n🚀 Processando dataset completo...\")\n        df_com_nanomateriais = processar_nanomateriais_dataframe(df, use_gemini=use_gemini)\n        \n        # Salvar resultado\n        arquivo_nanomateriais = 'df_com_nanomateriais_identificados.csv'\n        df_com_nanomateriais.to_csv(arquivo_nanomateriais, index=False)\n        print(f\"\\n💾 Resultado salvo em: {arquivo_nanomateriais}\")\n        \n        # Gerar estatísticas\n        print(f\"\\n📊 Gerando estatísticas...\")\n        stats = analisar_nanomateriais_com_estatisticas(df_com_nanomateriais)\n        \n        print(f\"\\n\" + \"=\"*50)\n        print(\"📈 ESTATÍSTICAS DE NANOMATERIAIS\")\n        print(\"=\"*50)\n        print(f\"Total de artigos: {stats['total_artigos']:,}\")\n        print(f\"Artigos com nanomateriais: {stats['artigos_com_nanomateriais']:,}\")\n        print(f\"Taxa de identificação: {stats['taxa_identificacao']:.1f}%\")\n        print(f\"Nanomateriais únicos: {stats['total_materiais_unicos']}\")\n        \n        print(f\"\\n🏆 Top 10 nanomateriais mais citados:\")\n        for i, (material, count) in enumerate(stats['materiais_mais_citados'], 1):\n            print(f\"  {i:2d}. {material}: {count} menções\")\n        \n        print(f\"\\n📂 Nanomateriais por categoria:\")\n        for categoria, materiais in stats['materiais_por_categoria'].items():\n            print(f\"\\n{categoria.replace('_', ' ').title()}:\")\n            for material, count in materiais[:3]:  # Top 3 por categoria\n                print(f\"  • {material}: {count} menções\")\n    \nelse:\n    print(\"❌ Dados não disponíveis ou coluna 'Abstract' não encontrada\")",
      "block_group": "ad5e7d587f644534b8d31fe123418384",
      "execution_count": null,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d35fdc8b-8543-45dc-ae25-3ba609dd01b9' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "848a9951670d45caa2f76f00e5ba2236"
  }
}